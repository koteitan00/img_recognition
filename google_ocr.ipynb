{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41c22aa-d628-4037-8f16-e68d16e05e54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Start Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf1c2e17-ea96-45fe-b65e-fb272c1f2851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "MIME_TYPE = 'application/vnd.google-apps.document'\n",
    "APPLICATION_NAME = 'ipa-google-drive-api-client'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992b6658-efd2-41b3-a71f-3f20fb8b97ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T14:53:53.138703Z",
     "start_time": "2023-05-23T14:53:53.097171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=177107319826-i8oj1jnq3najvtvm0prpb18ncuipamef.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A53613%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.file&state=MDS4s4JKteNzPEbHcy5FodZP2ZdRnL&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "def get_service():\n",
    "\n",
    "    # credentialの取得\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'google-drive-api.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "        \n",
    "    # serviceの取得\n",
    "    service = build('drive', 'v3', credentials=creds) \n",
    "    \n",
    "    return service\n",
    "\n",
    "def read_ocr(service, input_file, lang='jp'):\n",
    "    # ファイルのアップロード\n",
    "\n",
    "    # ローカルファイルの定義\n",
    "    media_body = MediaFileUpload(input_file, mimetype=MIME_TYPE, resumable=True)\n",
    "\n",
    "    # Google Drive上のファイル名\n",
    "    newfile = 'output.pdf'\n",
    "\n",
    "    body = {\n",
    "        'name': newfile,\n",
    "        'mimeType': MIME_TYPE\n",
    "    }\n",
    "\n",
    "    # 　creat関数でファイルアップロード実行\n",
    "    # 同時にOCR読み取りも行う\n",
    "    output = service.files().create(\n",
    "        body=body,\n",
    "        media_body=media_body,\n",
    "        # ここで読み込み先言語の指定を行う\n",
    "        ocrLanguage=lang,\n",
    "    ).execute()\n",
    "\n",
    "    # テキストファイルのダウンロード\n",
    "\n",
    "    # リクエストオブジェクト生成\n",
    "    request = service.files().export_media(\n",
    "        fileId=output['id'],\n",
    "        mimeType=\"text/plain\"\n",
    "    )\n",
    "    output_path = 'output.txt'\n",
    "\n",
    "    with open(output_path, 'a') as f:\n",
    "        fh = io.FileIO(output_path, \"wb\")\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "\n",
    "        service.files().delete(fileId=output['id']).execute()\n",
    "    \n",
    "        # テキストの取得\n",
    "    with open(output_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 読み取り結果のリストを返す\n",
    "    return lines[1:]\n",
    "\n",
    "\n",
    "service = get_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94045e0-35ba-4a5d-8254-d9a671c7339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_file(text_file):\n",
    "    output_dir = \"C:/Users/covid/text_recognition/output\"\n",
    "    if os.path.exists(output_dir):\n",
    "        file_list = [f for f in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, f))]\n",
    "        for file_name in file_list:\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "            os.remove(file_path)\n",
    "    else:\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with open(text_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        lines = sorted(lines, key=lambda line: float(line.split()[1]))\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            values = line.split()\n",
    "\n",
    "            if len(values) == 5:\n",
    "                object_class = values[0]\n",
    "                a = float(values[1])\n",
    "                b = float(values[2])\n",
    "                c = float(values[3])\n",
    "                d = float(values[4])\n",
    "\n",
    "                # Calculate coordinates and dimensions\n",
    "                x_center = int(wid * a)\n",
    "                y_center = int(hei * b)\n",
    "                width = int(wid * c)\n",
    "                height = int(hei * d)\n",
    "\n",
    "                x_min = x_center - width // 2\n",
    "                y_min = y_center - height // 2\n",
    "                x_max = x_center + width // 2\n",
    "                y_max = y_center + height // 2\n",
    "\n",
    "                output_filename = os.path.join(output_dir, f'book{i+1}.jpg')\n",
    "                index = 1\n",
    "                while os.path.exists(output_filename):\n",
    "                    output_filename = os.path.join(output_dir, f'book{i+1}_{index}.jpg')\n",
    "                    index += 1\n",
    "\n",
    "                # Crop and save the image\n",
    "                cropped = image.crop((x_min, y_min, x_max, y_max))\n",
    "                cropped.save(output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bac146-c454-4e03-989f-8a14ce1233ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## roboflowを使用したモデルのデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97f7cb49-6ba4-4fc2-9c87-05eb2c8d2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# passの設定 (pip showで出てきた、LocationのPASSを以下に設定)\n",
    "sys.path.append('c:/users/covid/anaconda3/lib/site-packages')\n",
    "\n",
    "# passの設定はimportするモジュールより前に設定\n",
    "import roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8bd6484-cb1e-49d9-b03d-a9124b324f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] アクセスが拒否されました。: 'C:\\\\Users\\\\covid\\\\anaconda3\\\\envs\\\\localGPU\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Using cached roboflow-1.1.36-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2023.7.22)\n",
      "Collecting chardet==4.0.0 (from roboflow)\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.26.1)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (10.1.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.26.19)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filetype in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (4.43.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from requests->roboflow) (3.3.1)\n",
      "Using cached roboflow-1.1.36-py3-none-any.whl (76 kB)\n",
      "Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: opencv-python-headless, idna, chardet, requests-toolbelt, roboflow\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in book-spine-detection-1 to yolov7pytorch:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 245898/245898 [00:10<00:00, 22409.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to book-spine-detection-1 in yolov7pytorch:: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7770/7770 [00:03<00:00, 2425.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#自身のモデル→versions→Export datasetにあるコードのコピペ\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"9RdognCaI8Nuh4bFkYHc\")\n",
    "project = rf.workspace(\"koteitan\").project(\"book-spine-detection-2cci9\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ac504-8e81-4b09-be8c-3202c0e5533b",
   "metadata": {},
   "source": [
    "今回作成したモデルはなぜか書籍検知行われず、一方で作成したモデルの使用方法は判明したので今後はroboflow側でモデルのチューニングを行って書籍の検知および精度の向上を頑張る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1bd4555-2651-444e-ac1d-8a395d6232db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "#wgetの代用\n",
    "import requests\n",
    "\n",
    "url = 'https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    with open('yolov7_training.pt', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print('File downloaded successfully')\n",
    "else:\n",
    "    print(f'Failed to download file. Status code: {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36df170a-1820-4174-a068-0b393d761262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  v0.1-126-g84932d7 torch 2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "Namespace(weights=\"'yolov7_training.pt'\", cfg='', data='data/coco.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=55, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs\\\\train\\\\exp2', total_batch_size=16)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\covid\\text_recognition\\yolov7\\train.py\", line 616, in <module>\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"C:\\Users\\covid\\text_recognition\\yolov7\\train.py\", line 95, in train\n",
      "    model = Model(opt.cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
      "  File \"C:\\Users\\covid\\text_recognition\\yolov7\\models\\yolo.py\", line 517, in __init__\n",
      "    with open(cfg) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: ''\n"
     ]
    }
   ],
   "source": [
    "!python train.py --device 0 --batch 16 --epochs 55 --data data/coco.yaml --weights 'yolov7_training.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3f7ecfe-78f7-440e-94cb-2f98c1cfb420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] アクセスが拒否されました。: 'C:\\\\Users\\\\covid\\\\anaconda3\\\\envs\\\\localGPU\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Using cached roboflow-1.1.36-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2023.7.22)\n",
      "Collecting chardet==4.0.0 (from roboflow)\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.26.1)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (10.1.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.26.19)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filetype in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (4.43.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from requests->roboflow) (3.3.1)\n",
      "Using cached roboflow-1.1.36-py3-none-any.whl (76 kB)\n",
      "Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: opencv-python-headless, idna, chardet, requests-toolbelt, roboflow\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"9RdognCaI8Nuh4bFkYHc\")\n",
    "project = rf.workspace(\"koteitan\").project(\"book-spine-detection-2cci9\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8-obb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4b9b2125-701a-40c7-8536-338f75bbef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0344617b-9714-440c-9bd2-f4ce6e0536f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (8.2.64)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (1.26.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (10.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (1.11.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (0.16.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (5.9.6)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2d63d943-12b1-43eb-9658-deea39a810d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9c83b064-aab9-4f9d-abdf-426ddf9a3732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 25 18:31:25 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.92                 Driver Version: 545.92       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   39C    P8              26W / 370W |   2256MiB / 24576MiB |     11%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1044    C+G   ...a\\Local\\slack\\app-4.39.89\\slack.exe    N/A      |\n",
      "|    0   N/A  N/A      1320    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      5116    C+G   ...t Office\\root\\Office16\\POWERPNT.EXE    N/A      |\n",
      "|    0   N/A  N/A      5956    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      7080    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     10184    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     11140    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13008    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13196    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13688    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     14756    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15104    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     15332    C+G   ...up\\ui-launcher\\AdskAccessUIHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16988    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe    N/A      |\n",
      "|    0   N/A  N/A     17636    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     20128    C+G   ...\\anaconda3\\envs\\localGPU\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     22264    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     23244    C+G   C:\\Windows\\PrintDialog\\PrintDialog.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f4cd7db5-c564-4150-b3d8-6a11865feaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b383225d-9fea-4f76-a3bc-1b2e5a674b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.64  Python-3.10.13 torch-2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "Setup complete  (8 CPUs, 31.9 GB RAM, 283.8/952.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics -q\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "94adfe6c-25a6-4d6b-8b8e-6987f10a2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "031a284c-8f10-484d-a42e-564ce6d79e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] 指定されたファイルが見つかりません。: 'C:\\\\Users\\\\covid\\\\text_recognition/datasets'\n",
      "C:\\Users\\covid\\text_recognition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "コマンドの構文が誤っています。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visit https://app.roboflow.com/auth-cli to get your authentication token.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste the authentication token here:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Aerial-Solar-Panels-6 to yolov8-obb:: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20272/20272 [00:02<00:00, 9527.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Aerial-Solar-Panels-6 in yolov8-obb:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 454/454 [00:00<00:00, 2286.66it/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "!pip install roboflow --quiet\n",
    "\n",
    "import roboflow\n",
    "\n",
    "roboflow.login()\n",
    "\n",
    "rf = roboflow.Roboflow()\n",
    "\n",
    "project = rf.workspace(\"brad-dwyer\").project(\"aerial-solar-panels\")\n",
    "dataset = project.version(6).download(\"yolov8-obb\")\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open(f'{dataset.location}/data.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "data['path'] = dataset.location\n",
    "\n",
    "with open(f'{dataset.location}/data.yaml', 'w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e4d5fccc-31fa-4d80-9e14-ea2e359a74fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.64  Python-3.10.13 torch-2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=obb, mode=train, model=yolov8n-obb.pt, data=C:\\Users\\covid\\text_recognition\\Aerial-Solar-Panels-6/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\obb\\train3\n",
      "Overriding model.yaml nc=15 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    823174  ultralytics.nn.modules.head.OBB              [1, 1, [64, 128, 256]]        \n",
      "YOLOv8n-obb summary: 250 layers, 3,082,710 parameters, 3,082,694 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 391/397 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\obb\\train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.amp' has no attribute 'GradScaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8n-obb.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/data.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\engine\\model.py:810\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\engine\\trainer.py:206\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\engine\\trainer.py:329\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp(world_size)\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[0;32m    332\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m*\u001b[39m nb), \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\engine\\trainer.py:270\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    267\u001b[0m     dist\u001b[38;5;241m.\u001b[39mbroadcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp, src\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# broadcast the tensor from rank 0 to all other ranks (returns None)\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp)  \u001b[38;5;66;03m# as boolean\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 270\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGradScaler\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mGradScaler(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp)\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39mDistributedDataParallel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, device_ids\u001b[38;5;241m=\u001b[39m[RANK], find_unused_parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.amp' has no attribute 'GradScaler'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-obb.pt')\n",
    "\n",
    "results = model.train(data=f\"{dataset.location}/data.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b9855afd-d9fe-4b38-867c-c8ed22a757bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs\\\\obb\\\\train\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruns/obb/train/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\models\\yolo\\model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\engine\\model.py:141\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\engine\\model.py:293\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    290\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\nn\\tasks.py:855\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    854\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\nn\\tasks.py:781\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m    771\u001b[0m         modules\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    779\u001b[0m         },\n\u001b[0;32m    780\u001b[0m     ):\n\u001b[1;32m--> 781\u001b[0m         ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\ultralytics\\utils\\patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _torch_load(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\torch\\serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\torch\\serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localGPU\\lib\\site-packages\\torch\\serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs\\\\obb\\\\train\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "model = YOLO('runs/obb/train/weights/best.pt')\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "random_file = random.choice(os.listdir(f\"{dataset.location}/test/images\"))\n",
    "file_name = os.path.join(f\"{dataset.location}/test/images\", random_file)\n",
    "\n",
    "results = model(file_name)\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0b8d549f-29de-4cda-b3d6-1725b3b950ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Using cached roboflow-1.1.36-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2023.7.22)\n",
      "Collecting chardet==4.0.0 (from roboflow)\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.26.1)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (10.1.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.26.19)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filetype in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (4.43.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from requests->roboflow) (3.3.1)\n",
      "Using cached roboflow-1.1.36-py3-none-any.whl (76 kB)\n",
      "Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: opencv-python-headless, idna, chardet, requests-toolbelt, roboflow\n",
      "Successfully installed chardet-4.0.0 idna-3.7 opencv-python-headless-4.10.0.84 requests-toolbelt-1.0.0 roboflow-1.1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script chardetect.exe is installed in 'C:\\Users\\covid\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script roboflow.exe is installed in 'C:\\Users\\covid\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow --user\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"9RdognCaI8Nuh4bFkYHc\")\n",
    "project = rf.workspace(\"koteitan\").project(\"book-spine-detection-2cci9\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8-obb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb485bc-c0e7-48d0-a7a0-3c91829352f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo obb train data=/content/drive/MyDrive/AxrossRecipe/neji_obb/data.yaml pretrained=yolov8n-obb.pt epochs=100 imgsz=640 exist_ok=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbdca0-abe2-41e8-ab29-9c0d0a553d1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde91463-c141-461e-9d3d-af02f4c1a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable list\n",
    "# ディレクトリのパス\n",
    "directory_path = \"C:/Users/covid/text_recognition/yolov7/runs/detect\"\n",
    "# 画像ファイルの相対パスを指定\n",
    "image_relative_path = \"input.png\"\n",
    "# テキストファイルの相対パスを指定\n",
    "text_file_relative_path = \"labels/input.txt\"\n",
    "\n",
    "out_path = 'C:/Users/covid/text_recognition/output'\n",
    "output_file = \"C:/Users/covid/text_recognition/output_results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b9ce244-8ea8-462f-b9a1-97f0c7b7b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "cv2.imwrite(\"C:/Users/covid/text_recognition/yolov7/input.png\",frame)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddd81928-34a6-4223-9e45-7c8283efac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\\yolov7\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\covid\\text_recognition\\yolov7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3110c241-2cb6-4e63-8ee7-9ba5c3844d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ内のサブディレクトリのリストを取得\n",
    "subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "# サブディレクトリの中で一番新しいものを取得\n",
    "newest_subdirectory = max(subdirectories, key=lambda d: os.path.getctime(os.path.join(directory_path, d)))\n",
    "\n",
    "# 最新のサブディレクトリのパスを作成\n",
    "newest_subdirectory_path = os.path.join(directory_path, newest_subdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3504fcd-93e7-427a-944d-161d4f3b56fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['yolov7-e6e.pt'], source='C:/Users/covid/text_recognition/yolov7/input.png', img_size=1280, conf_thres=0.25, iou_thres=0.45, device='0', view_img=False, save_txt=True, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
      "Fusing layers... \n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "1 chair, 6 books, Done. (42.3ms) Inference, (47.9ms) NMS\n",
      " The image with the result is saved in: runs\\detect\\exp79\\input.png\n",
      "Done. (0.501s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  v0.1-126-g84932d7 torch 2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "C:\\Users\\covid\\anaconda3\\envs\\localGPU\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 792 layers, 151687420 parameters, 817020 gradients, 210.5 GFLOPS\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source C:/Users/covid/text_recognition/yolov7/input.png --weights yolov7-e6e.pt --conf 0.25 --img-size 1280 --device 0 --save-txt\n",
    "#本来なら学習した結果重みが新しく生成されるはずでは？？次回調査する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a969b25e-5808-4302-b953-23c04b4cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ内のサブディレクトリのリストを取得\n",
    "subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "# サブディレクトリの中で一番新しいものを取得\n",
    "newest_subdirectory = max(subdirectories, key=lambda d: os.path.getctime(os.path.join(directory_path, d)))\n",
    "\n",
    "# 最新のサブディレクトリのパスを作成\n",
    "newest_subdirectory_path = os.path.join(directory_path, newest_subdirectory)\n",
    "# 新しいディレクトリに移動\n",
    "os.chdir(newest_subdirectory_path)\n",
    "\n",
    "# 画像ファイルの絶対パスを作成\n",
    "image_absolute_path = os.path.join(newest_subdirectory_path, image_relative_path)\n",
    "# テキストファイルの絶対パスを作成\n",
    "text_file_absolute_path = os.path.join(newest_subdirectory_path, text_file_relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a5e8364-98bc-433b-b7da-7a7d3d80f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像をImageクラスのインスタンスに読み込む\n",
    "image = Image.open(image_absolute_path)\n",
    "# テキストファイルを読み込む\n",
    "with open(text_file_absolute_path, 'r') as file:\n",
    "    text_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e30fd2d9-71f2-47b1-a602-2b1d9b7c14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text file\n",
    "wid,hei = image.size\n",
    "process_text_file(text_file_absolute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "999c5e72-1c01-446e-bec0-a6bc50775a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output corresponding to list format\n",
    "if __name__ == '__main__':\n",
    "    output_list = []\n",
    "\n",
    "    file_list = [filename for filename in os.listdir(out_path) if filename.endswith('.jpg')]\n",
    "    file_list.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "    for filename in file_list:\n",
    "        input_file = os.path.join(out_path, filename)\n",
    "        output = read_ocr(service, input_file, 'ja')\n",
    "\n",
    "        # 不要な文字（スペースとバックスラッシュ）を除去して一つの文字列に結合する\n",
    "        cleaned_output = ''.join(line.strip().replace(' ', '').replace('/', '').replace('\\n', '').replace('\\\\', '') for line in output)\n",
    "\n",
    "        # 結果をリストに追加\n",
    "        output_list.append(cleaned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4e40376-a25b-4581-beb2-9e987664e456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:/Users/covid/text_recognition/output_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the results to the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for result in output_list:\n",
    "            file.write(result + '\\n')\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a8433c-74fa-4409-9410-da659b44c5d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare NLP Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e791e-ffb3-4710-89d3-d281d8017ba6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Different.SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0b25da00-05b8-4cb9-9cbd-fd60b655e24d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\\\Users\\\\covid\\\\text_recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "701f522b-4abb-4bd9-a9d1-53415a4b2590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text A (line 1): 책의문화\n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.1429\n",
      "\n",
      "Text A (line 2): 책의괴의세계사\n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.1176\n",
      "\n",
      "Text A (line 3): 책파괴의세계사미래\n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.1053\n",
      "\n",
      "Text A (line 4): Book파괴의세계사책의미래케의미래\n",
      "Best Match in Text B (line 42): IOBOOKSROSではじめるロボットプログラミングDownLoad小倉崇工学社\n",
      "Highest Similarity Ratio: 0.1333\n",
      "\n",
      "Text A (line 5): BookBook책의미래L정신\n",
      "Best Match in Text B (line 68): MasteringROSforRoboticsProgrammingLentinJosephPACKT*\n",
      "Highest Similarity Ratio: 0.1739\n",
      "\n",
      "Text A (line 6): Book책의정신책의정신\n",
      "Best Match in Text B (line 42): IOBOOKSROSではじめるロボットプログラミングDownLoad小倉崇工学社\n",
      "Highest Similarity Ratio: 0.1481\n",
      "\n",
      "Text A (line 7): 책의정신\n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.1429\n",
      "\n",
      "Text A (line 8): \n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.2000\n",
      "\n",
      "Text A (line 9): 중독자의고백\n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.1250\n",
      "\n",
      "Text A (line 10): 连体백중독자의고백어느책중독자의고백1\n",
      "Best Match in Text B (line 75): 2019入学試験問題集千葉工業大学\n",
      "Highest Similarity Ratio: 0.1053\n",
      "\n",
      "Text A (line 11): 어느책중독자의\n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.1176\n",
      "\n",
      "Text A (line 12): \n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.2000\n",
      "\n",
      "Text A (line 13): \n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.2000\n",
      "\n",
      "Text A (line 14): 200ARE\n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.2500\n",
      "\n",
      "Text A (line 15): \n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.2000\n",
      "\n",
      "Text A (line 16): \n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.2000\n",
      "\n",
      "Text A (line 17): \n",
      "Best Match in Text B (line 129): 合格平成29年度\n",
      "Highest Similarity Ratio: 0.2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "        best_match_text_b = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = difflib.SequenceMatcher(None, text_a, text_b).ratio()\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "                best_match_text_b = text_b\n",
    "\n",
    "        print(f\"Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        print(f\"Best Match in Text B (line {lines_b.index(best_match) + 1}): {best_match.strip()}\")\n",
    "        print(f\"Highest Similarity Ratio: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e727c425-5ef0-4898-a436-836db1771d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "    output_file = \"output_similarity.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for index_a, text_a in enumerate(lines_a):\n",
    "            for index_b, text_b in enumerate(lines_b):\n",
    "                similarity = difflib.SequenceMatcher(None, text_a, text_b).ratio()\n",
    "\n",
    "                output.write(f\"Text A (line {index_a + 1}): {text_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {index_b + 1}): {text_b.strip()}\\n\")\n",
    "                output.write(f\"Similarity Ratio: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7afaa8-03cb-41ba-9122-46a2d0c15d05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b026ed89-2870-4469-9be3-05b8818d9871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text A (line 1): ポイント代キーポイント散キーポイント統計のための行列代数四ツ谷伊\n",
      "Best Match for Text A (line 1): キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Similarity Ratio: 0.4000\n",
      "\n",
      "Original Text A (line 2): 新応用数学Applied微分積分IIRHDifferentialIntegralシト線形代数AlgerIntegral1四ツ谷二\n",
      "Best Match for Text A (line 2): 新微分積分IDifferentialANDIntegralI大日本図書\n",
      "Highest Similarity Ratio: 0.5455\n",
      "\n",
      "Original Text A (line 3): 基礎数学FundamentalMathematics.新応用数学Appliedhematica微分積分IntegralTRHDifferentialintegralポイント代四ツ谷キーポイントポイント四ツ谷二統計のための行列代数リバーヴィル伊KIDWES\n",
      "Best Match for Text A (line 3): 新基礎数学FundamentalMathematics大日本図書\n",
      "Highest Similarity Ratio: 0.3270\n",
      "\n",
      "Original Text A (line 4): 基礎数学FundamentalMathematics.Appliedematics,\n",
      "Best Match for Text A (line 4): 新基礎数学FundamentalMathematics大日本図書\n",
      "Highest Similarity Ratio: 0.7027\n",
      "\n",
      "Original Text A (line 5): \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHighest Similarity Ratio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_similarity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 25\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         best_match \u001b[38;5;241m=\u001b[39m text_b\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Text A (line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_a\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_a\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Match for Text A (line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_a\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbest_match\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHighest Similarity Ratio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_similarity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = Levenshtein.ratio(text_a.strip(), text_b.strip())\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "\n",
    "        print(f\"Original Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        print(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\")\n",
    "        print(f\"Highest Similarity Ratio: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1a02a-d969-41cc-9259-99c68cd0197d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "    output_file = \"levenshtein_similarity.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for index_a, text_a in enumerate(lines_a):\n",
    "            max_similarity = 0.0\n",
    "            best_match = None\n",
    "\n",
    "            for index_b, text_b in enumerate(lines_b):\n",
    "                similarity = Levenshtein.ratio(text_a.strip(), text_b.strip())\n",
    "\n",
    "                output.write(f\"Text A (line {index_a + 1}): {text_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {index_b + 1}): {text_b.strip()}\\n\")\n",
    "                output.write(f\"Similarity Ratio: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    best_match = text_b\n",
    "\n",
    "            output.write(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\\n\")\n",
    "            output.write(f\"Highest Similarity Ratio: {max_similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10ac69-6023-489f-b011-da3a9cdf0fbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec8f9cc-613e-4429-9362-5e3806445fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jaccard_coefficient(s1, s2):\n",
    "    set1 = set(s1)\n",
    "    set2 = set(s2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = jaccard_coefficient(text_a.strip(), text_b.strip())\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "\n",
    "        print(f\"Original Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        print(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\")\n",
    "        print(f\"Highest Jaccard Coefficient: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f1222-e91f-434b-bea1-228250c67966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "    output_file = \"jaccard_similarity.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for index_a, text_a in enumerate(lines_a):\n",
    "            for index_b, text_b in enumerate(lines_b):\n",
    "                similarity = jaccard_coefficient(text_a.strip(), text_b.strip())\n",
    "\n",
    "                output.write(f\"Text A (line {index_a + 1}): {text_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {index_b + 1}): {text_b.strip()}\\n\")\n",
    "                output.write(f\"Jaccard Coefficient: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ee634-7830-4b7a-b93f-a49c73cd1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coefficient(s1, s2):\n",
    "    set1 = set(s1)\n",
    "    set2 = set(s2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        # 空白の行をスキップ\n",
    "        if not text_a.strip():\n",
    "            continue\n",
    "\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = jaccard_coefficient(text_a.strip(), text_b.strip())\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "\n",
    "        print(f\"Original Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        \n",
    "        if best_match is not None:\n",
    "            print(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\")\n",
    "            print(f\"Highest Jaccard Coefficient: {max_similarity:.4f}\\n\")\n",
    "        else:\n",
    "            print(\"No matching text found.\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138d09b-6749-46c9-a90d-7e1e3ef7af2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "localGPU",
   "language": "python",
   "name": "localgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
