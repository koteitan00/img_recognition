{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41c22aa-d628-4037-8f16-e68d16e05e54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f92ed15-9fc6-4f11-9e00-3c09a2299042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118 True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1c2e17-ea96-45fe-b65e-fb272c1f2851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "MIME_TYPE = 'application/vnd.google-apps.document'\n",
    "APPLICATION_NAME = 'ipa-google-drive-api-client'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd46a61e-888d-40f4-ae2a-1e6458c4455b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T14:53:53.138703Z",
     "start_time": "2023-05-23T14:53:53.097171Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\covid\\text_recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992b6658-efd2-41b3-a71f-3f20fb8b97ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T14:53:53.138703Z",
     "start_time": "2023-05-23T14:53:53.097171Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_service():\n",
    "\n",
    "    # credentialの取得\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'google-drive-api.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "        \n",
    "    # serviceの取得\n",
    "    service = build('drive', 'v3', credentials=creds) \n",
    "    \n",
    "    return service\n",
    "\n",
    "def read_ocr(service, input_file, lang='jp'):\n",
    "    # ファイルのアップロード\n",
    "\n",
    "    # ローカルファイルの定義\n",
    "    media_body = MediaFileUpload(input_file, mimetype=MIME_TYPE, resumable=True)\n",
    "\n",
    "    # Google Drive上のファイル名\n",
    "    newfile = 'output.pdf'\n",
    "\n",
    "    body = {\n",
    "        'name': newfile,\n",
    "        'mimeType': MIME_TYPE\n",
    "    }\n",
    "\n",
    "    # 　creat関数でファイルアップロード実行\n",
    "    # 同時にOCR読み取りも行う\n",
    "    output = service.files().create(\n",
    "        body=body,\n",
    "        media_body=media_body,\n",
    "        # ここで読み込み先言語の指定を行う\n",
    "        ocrLanguage=lang,\n",
    "    ).execute()\n",
    "\n",
    "    # テキストファイルのダウンロード\n",
    "\n",
    "    # リクエストオブジェクト生成\n",
    "    request = service.files().export_media(\n",
    "        fileId=output['id'],\n",
    "        mimeType=\"text/plain\"\n",
    "    )\n",
    "    output_path = 'output.txt'\n",
    "\n",
    "    with open(output_path, 'a') as f:\n",
    "        fh = io.FileIO(output_path, \"wb\")\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "\n",
    "        service.files().delete(fileId=output['id']).execute()\n",
    "    \n",
    "        # テキストの取得\n",
    "    with open(output_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 読み取り結果のリストを返す\n",
    "    return lines[1:]\n",
    "\n",
    "\n",
    "service = get_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e94045e0-35ba-4a5d-8254-d9a671c7339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_file(text_file):\n",
    "    output_dir = \"C:/Users/covid/text_recognition/output\"\n",
    "    if os.path.exists(output_dir):\n",
    "        file_list = [f for f in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, f))]\n",
    "        for file_name in file_list:\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "            os.remove(file_path)\n",
    "    else:\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with open(text_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        lines = sorted(lines, key=lambda line: float(line.split()[1]))\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            values = line.split()\n",
    "\n",
    "            if len(values) == 5:\n",
    "                object_class = values[0]\n",
    "                a = float(values[1])\n",
    "                b = float(values[2])\n",
    "                c = float(values[3])\n",
    "                d = float(values[4])\n",
    "\n",
    "                # Calculate coordinates and dimensions\n",
    "                x_center = int(wid * a)\n",
    "                y_center = int(hei * b)\n",
    "                width = int(wid * c)\n",
    "                height = int(hei * d)\n",
    "\n",
    "                x_min = x_center - width // 2\n",
    "                y_min = y_center - height // 2\n",
    "                x_max = x_center + width // 2\n",
    "                y_max = y_center + height // 2\n",
    "\n",
    "                output_filename = os.path.join(output_dir, f'book{i+1}.jpg')\n",
    "                index = 1\n",
    "                while os.path.exists(output_filename):\n",
    "                    output_filename = os.path.join(output_dir, f'book{i+1}_{index}.jpg')\n",
    "                    index += 1\n",
    "\n",
    "                # Crop and save the image\n",
    "                cropped = image.crop((x_min, y_min, x_max, y_max))\n",
    "                cropped.save(output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bac146-c454-4e03-989f-8a14ce1233ab",
   "metadata": {},
   "source": [
    "## roboflowを使用したモデルのデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f7cb49-6ba4-4fc2-9c87-05eb2c8d2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# passの設定 (pip showで出てきた、LocationのPASSを以下に設定)\n",
    "sys.path.append('c:/users/covid/anaconda3/lib/site-packages')\n",
    "\n",
    "# passの設定はimportするモジュールより前に設定\n",
    "import roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8bd6484-cb1e-49d9-b03d-a9124b324f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Using cached roboflow-1.1.34-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2023.7.22)\n",
      "Collecting chardet==4.0.0 (from roboflow)\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.26.1)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (10.1.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (1.26.19)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-magic in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from roboflow) (0.4.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (4.43.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from matplotlib->roboflow) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\covid\\anaconda3\\envs\\localgpu\\lib\\site-packages (from requests->roboflow) (3.3.1)\n",
      "Using cached roboflow-1.1.34-py3-none-any.whl (76 kB)\n",
      "Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: opencv-python-headless, idna, chardet, requests-toolbelt, roboflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] アクセスが拒否されました。: 'C:\\\\Users\\\\covid\\\\anaconda3\\\\envs\\\\localGPU\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in oriented-books-1 to yolov7pytorch:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27969/27969 [00:02<00:00, 10926.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to oriented-books-1 in yolov7pytorch:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1334/1334 [00:00<00:00, 2644.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#自身のモデル→versions→Export datasetにあるコードのコピペ\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"9RdognCaI8Nuh4bFkYHc\")\n",
    "project = rf.workspace(\"koteitan\").project(\"oriented-books\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ac504-8e81-4b09-be8c-3202c0e5533b",
   "metadata": {},
   "source": [
    "今回作成したモデルはなぜか書籍検知行われず、一方で作成したモデルの使用方法は判明したので今後はroboflow側でモデルのチューニングを行って"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1bd4555-2651-444e-ac1d-8a395d6232db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    with open('yolov7_training.pt', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print('File downloaded successfully')\n",
    "else:\n",
    "    print(f'Failed to download file. Status code: {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebee9ef4-0e99-4dc5-adeb-82f1c3c91171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\\yolov7\n"
     ]
    }
   ],
   "source": [
    "cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36df170a-1820-4174-a068-0b393d761262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  v0.1-126-g84932d7 torch 2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "Namespace(weights=\"'yolov7_training.pt'\", cfg='', data='data/coco.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=55, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs\\\\train\\\\exp', total_batch_size=16)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\covid\\text_recognition\\yolov7\\train.py\", line 616, in <module>\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"C:\\Users\\covid\\text_recognition\\yolov7\\train.py\", line 95, in train\n",
      "    model = Model(opt.cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
      "  File \"C:\\Users\\covid\\text_recognition\\yolov7\\models\\yolo.py\", line 517, in __init__\n",
      "    with open(cfg) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: ''\n"
     ]
    }
   ],
   "source": [
    "!python train.py --device 0 --batch 16 --epochs 55 --data data/coco.yaml --weights 'yolov7_training.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbdca0-abe2-41e8-ab29-9c0d0a553d1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bde91463-c141-461e-9d3d-af02f4c1a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable list\n",
    "# ディレクトリのパス\n",
    "directory_path = \"C:/Users/covid/text_recognition/yolov7/runs/detect\"\n",
    "# 画像ファイルの相対パスを指定\n",
    "image_relative_path = \"input.png\"\n",
    "# テキストファイルの相対パスを指定\n",
    "text_file_relative_path = \"labels/input.txt\"\n",
    "\n",
    "out_path = 'C:/Users/covid/text_recognition/output'\n",
    "output_file = \"C:/Users/covid/text_recognition/output_results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b9ce244-8ea8-462f-b9a1-97f0c7b7b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "cv2.imwrite(\"C:/Users/covid/text_recognition/yolov7/input.png\",frame)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddd81928-34a6-4223-9e45-7c8283efac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\\yolov7\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\covid\\text_recognition\\yolov7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3110c241-2cb6-4e63-8ee7-9ba5c3844d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ内のサブディレクトリのリストを取得\n",
    "subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "# サブディレクトリの中で一番新しいものを取得\n",
    "newest_subdirectory = max(subdirectories, key=lambda d: os.path.getctime(os.path.join(directory_path, d)))\n",
    "\n",
    "# 最新のサブディレクトリのパスを作成\n",
    "newest_subdirectory_path = os.path.join(directory_path, newest_subdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3504fcd-93e7-427a-944d-161d4f3b56fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['yolov7-e6e.pt'], source='C:/Users/covid/text_recognition/yolov7/input.png', img_size=1280, conf_thres=0.25, iou_thres=0.45, device='0', view_img=False, save_txt=True, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
      "Fusing layers... \n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "1 person, 1 tv, 1 keyboard, Done. (27.0ms) Inference, (48.5ms) NMS\n",
      " The image with the result is saved in: runs\\detect\\exp70\\input.png\n",
      "Done. (0.458s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  v0.1-126-g84932d7 torch 2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "Model Summary: 792 layers, 151687420 parameters, 817020 gradients\n",
      "C:\\Users\\covid\\anaconda3\\envs\\localGPU\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source C:/Users/covid/text_recognition/yolov7/input.png --weights yolov7-e6e.pt --conf 0.25 --img-size 1280 --device 0 --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a969b25e-5808-4302-b953-23c04b4cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ内のサブディレクトリのリストを取得\n",
    "subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "# サブディレクトリの中で一番新しいものを取得\n",
    "newest_subdirectory = max(subdirectories, key=lambda d: os.path.getctime(os.path.join(directory_path, d)))\n",
    "\n",
    "# 最新のサブディレクトリのパスを作成\n",
    "newest_subdirectory_path = os.path.join(directory_path, newest_subdirectory)\n",
    "# 新しいディレクトリに移動\n",
    "os.chdir(newest_subdirectory_path)\n",
    "\n",
    "# 画像ファイルの絶対パスを作成\n",
    "image_absolute_path = os.path.join(newest_subdirectory_path, image_relative_path)\n",
    "# テキストファイルの絶対パスを作成\n",
    "text_file_absolute_path = os.path.join(newest_subdirectory_path, text_file_relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a8717cc-c4e0-46c3-9e7f-323abd61f69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:/Users/covid/text_recognition/yolov7/runs/detect\\exp70\\input.png\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(image_absolute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a5e8364-98bc-433b-b7da-7a7d3d80f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像をImageクラスのインスタンスに読み込む\n",
    "image = Image.open(image_absolute_path)\n",
    "# テキストファイルを読み込む\n",
    "with open(text_file_absolute_path, 'r') as file:\n",
    "    text_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e30fd2d9-71f2-47b1-a602-2b1d9b7c14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text file\n",
    "wid,hei = image.size\n",
    "process_text_file(text_file_absolute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "999c5e72-1c01-446e-bec0-a6bc50775a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output corresponding to list format\n",
    "if __name__ == '__main__':\n",
    "    output_list = []\n",
    "\n",
    "    file_list = [filename for filename in os.listdir(out_path) if filename.endswith('.jpg')]\n",
    "    file_list.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "    for filename in file_list:\n",
    "        input_file = os.path.join(out_path, filename)\n",
    "        output = read_ocr(service, input_file, 'ja')\n",
    "\n",
    "        # 不要な文字（スペースとバックスラッシュ）を除去して一つの文字列に結合する\n",
    "        cleaned_output = ''.join(line.strip().replace(' ', '').replace('/', '').replace('\\n', '').replace('\\\\', '') for line in output)\n",
    "\n",
    "        # 結果をリストに追加\n",
    "        output_list.append(cleaned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4e40376-a25b-4581-beb2-9e987664e456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:/Users/covid/text_recognition/output_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the results to the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for result in output_list:\n",
    "            file.write(result + '\\n')\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a8433c-74fa-4409-9410-da659b44c5d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare NLP Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e791e-ffb3-4710-89d3-d281d8017ba6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Different.SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0b25da00-05b8-4cb9-9cbd-fd60b655e24d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\\\Users\\\\covid\\\\text_recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "701f522b-4abb-4bd9-a9d1-53415a4b2590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text A (line 1): 新明解C言語入門編柴田\n",
      "Best Match in Text B (line 31): 新・明解C言語入門編柴田望洋SBCreative\n",
      "Highest Similarity Ratio: 0.6486\n",
      "\n",
      "Text A (line 2): 解きながら学ぶC言明解きながら学ぶC言語柴田望\n",
      "Best Match in Text B (line 32): 解きながら学ぶC言語柴田望洋[監修・著]赤尾浩・肘井信一・高木宏典[著]SBCreative\n",
      "Highest Similarity Ratio: 0.3944\n",
      "\n",
      "Text A (line 3): プログラミングROSPythonによるロボットアプリケーション開発MorganQuigleyBrianGerkeyWilliamD.Smart\n",
      "Best Match in Text B (line 35): プログラミングROSPythonによるロボットアプリケーション開発MorganQuigleyBrianGerkeyWilliamD.Smart河田卓志監訳松田晃一、福地正樹、由谷哲夫訳O'REILLY\n",
      "Highest Similarity Ratio: 0.8324\n",
      "\n",
      "Text A (line 4): KINECTforWindowsSDKプログラミングC++編\n",
      "Best Match in Text B (line 41): KINECTforWindowsSDKプログラミングC++編株式会社ゲッシュ中村薰齋藤俊太宮城英人〈著>システム\n",
      "Highest Similarity Ratio: 0.7045\n",
      "\n",
      "Text A (line 5): C++111410刷\n",
      "Best Match in Text B (line 51): C++1114コア言語10刷突破!C++入門書のロングセラー!!~.マイナビ\n",
      "Highest Similarity Ratio: 0.4400\n",
      "\n",
      "Text A (line 6): CUDACCUDAの機能・手法をプロフェッショナルプログラミング網羅的に解説!\n",
      "Best Match in Text B (line 73): CUDACプロフェッショナルプログラミングCUDAの機能・手法を網羅的に解説!\n",
      "Highest Similarity Ratio: 0.7250\n",
      "\n",
      "Text A (line 7): HOTELE言語実装パターンコンパイラ技術によるテキスト処理か言語実装までらTem\n",
      "Best Match in Text B (line 74): 言語実装パターンコンパイラ技術によるテキスト処理から言語実装までTerence Parr著中田育男監訳伊藤真浩訳O'Reilly\n",
      "Highest Similarity Ratio: 0.6355\n",
      "\n",
      "Text A (line 8): 詳解OpenCV3コンピュータビジョンライブラリを使った画像処理・認識永松G\n",
      "Best Match in Text B (line 52): 詳解OpenCV3AdrianKaehlerGaryBradski松田晃一、小沼千絵著永田雅人、花形理訳O'REILLY\n",
      "Highest Similarity Ratio: 0.2200\n",
      "\n",
      "Text A (line 9): リスク評価と危機管理ネットワークバ\n",
      "Best Match in Text B (line 53): 実践ネットワークセキュリティ監査リスク評価と危機管理ChrisMcNab著鍋島公章監訳(株)ネットワークバリューコンポネンツ訳O'REILLY\n",
      "Highest Similarity Ratio: 0.4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "        best_match_text_b = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = difflib.SequenceMatcher(None, text_a, text_b).ratio()\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "                best_match_text_b = text_b\n",
    "\n",
    "        print(f\"Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        print(f\"Best Match in Text B (line {lines_b.index(best_match) + 1}): {best_match.strip()}\")\n",
    "        print(f\"Highest Similarity Ratio: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e727c425-5ef0-4898-a436-836db1771d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "    output_file = \"output_similarity.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for index_a, text_a in enumerate(lines_a):\n",
    "            for index_b, text_b in enumerate(lines_b):\n",
    "                similarity = difflib.SequenceMatcher(None, text_a, text_b).ratio()\n",
    "\n",
    "                output.write(f\"Text A (line {index_a + 1}): {text_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {index_b + 1}): {text_b.strip()}\\n\")\n",
    "                output.write(f\"Similarity Ratio: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7afaa8-03cb-41ba-9122-46a2d0c15d05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b026ed89-2870-4469-9be3-05b8818d9871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text A (line 1): 新明解C言語入門編柴田\n",
      "Best Match for Text A (line 1): 新・明解C言語入門編柴田望洋SBCreative\n",
      "Highest Similarity Ratio: 0.6286\n",
      "\n",
      "Original Text A (line 2): 解きながら学ぶC言明解きながら学ぶC言語柴田望\n",
      "Best Match for Text A (line 2): 解きながら学ぶC言語柴田望洋[監修・著]赤尾浩・肘井信一・高木宏典[著]SBCreative\n",
      "Highest Similarity Ratio: 0.3768\n",
      "\n",
      "Original Text A (line 3): プログラミングROSPythonによるロボットアプリケーション開発MorganQuigleyBrianGerkeyWilliamD.Smart\n",
      "Best Match for Text A (line 3): プログラミングROSPythonによるロボットアプリケーション開発MorganQuigleyBrianGerkeyWilliamD.Smart河田卓志監訳松田晃一、福地正樹、由谷哲夫訳O'REILLY\n",
      "Highest Similarity Ratio: 0.8304\n",
      "\n",
      "Original Text A (line 4): KINECTforWindowsSDKプログラミングC++編\n",
      "Best Match for Text A (line 4): KINECTforWindowsSDKプログラミングC++編株式会社ゲッシュ中村薰齋藤俊太宮城英人〈著>システム\n",
      "Highest Similarity Ratio: 0.6977\n",
      "\n",
      "Original Text A (line 5): C++111410刷\n",
      "Best Match for Text A (line 5): C++1114コア言語10刷突破!C++入門書のロングセラー!!~.マイナビ\n",
      "Highest Similarity Ratio: 0.4167\n",
      "\n",
      "Original Text A (line 6): CUDACCUDAの機能・手法をプロフェッショナルプログラミング網羅的に解説!\n",
      "Best Match for Text A (line 6): CUDACプロフェッショナルプログラミングCUDAの機能・手法を網羅的に解説!\n",
      "Highest Similarity Ratio: 0.7179\n",
      "\n",
      "Original Text A (line 7): HOTELE言語実装パターンコンパイラ技術によるテキスト処理か言語実装までらTem\n",
      "Best Match for Text A (line 7): 言語実装パターンコンパイラ技術によるテキスト処理から言語実装までTerence Parr著中田育男監訳伊藤真浩訳O'Reilly\n",
      "Highest Similarity Ratio: 0.6286\n",
      "\n",
      "Original Text A (line 8): 詳解OpenCV3コンピュータビジョンライブラリを使った画像処理・認識永松G\n",
      "Best Match for Text A (line 8): 詳解OpenCV3AdrianKaehlerGaryBradski松田晃一、小沼千絵著永田雅人、花形理訳O'REILLY\n",
      "Highest Similarity Ratio: 0.2041\n",
      "\n",
      "Original Text A (line 9): リスク評価と危機管理ネットワークバ\n",
      "Best Match for Text A (line 9): 実践ネットワークセキュリティ監査リスク評価と危機管理ChrisMcNab著鍋島公章監訳(株)ネットワークバリューコンポネンツ訳O'REILLY\n",
      "Highest Similarity Ratio: 0.3864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = Levenshtein.ratio(text_a.strip(), text_b.strip())\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "\n",
    "        print(f\"Original Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        print(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\")\n",
    "        print(f\"Highest Similarity Ratio: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d9b1a02a-d969-41cc-9259-99c68cd0197d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "    output_file = \"levenshtein_similarity.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for index_a, text_a in enumerate(lines_a):\n",
    "            max_similarity = 0.0\n",
    "            best_match = None\n",
    "\n",
    "            for index_b, text_b in enumerate(lines_b):\n",
    "                similarity = Levenshtein.ratio(text_a.strip(), text_b.strip())\n",
    "\n",
    "                output.write(f\"Text A (line {index_a + 1}): {text_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {index_b + 1}): {text_b.strip()}\\n\")\n",
    "                output.write(f\"Similarity Ratio: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    best_match = text_b\n",
    "\n",
    "            output.write(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\\n\")\n",
    "            output.write(f\"Highest Similarity Ratio: {max_similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10ac69-6023-489f-b011-da3a9cdf0fbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "cec8f9cc-613e-4429-9362-5e3806445fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text A (line 1): 新明解C言語入門編柴田\n",
      "Best Match for Text A (line 1): 新・明解C言語入門編柴田望洋SBCreative\n",
      "Highest Jaccard Coefficient: 0.5000\n",
      "\n",
      "Original Text A (line 2): 解きながら学ぶC言明解きながら学ぶC言語柴田望\n",
      "Best Match for Text A (line 2): 解きながら学ぶC言語柴田望洋[監修・著]赤尾浩・肘井信一・高木宏典[著]SBCreative\n",
      "Highest Jaccard Coefficient: 0.3250\n",
      "\n",
      "Original Text A (line 3): プログラミングROSPythonによるロボットアプリケーション開発MorganQuigleyBrianGerkeyWilliamD.Smart\n",
      "Best Match for Text A (line 3): プログラミングROSPythonによるロボットアプリケーション開発MorganQuigleyBrianGerkeyWilliamD.Smart河田卓志監訳松田晃一、福地正樹、由谷哲夫訳O'REILLY\n",
      "Highest Jaccard Coefficient: 0.6618\n",
      "\n",
      "Original Text A (line 4): KINECTforWindowsSDKプログラミングC++編\n",
      "Best Match for Text A (line 4): KINECTforWindowsSDKプログラミングC++編株式会社ゲッシュ中村薰齋藤俊太宮城英人〈著>システム\n",
      "Highest Jaccard Coefficient: 0.5000\n",
      "\n",
      "Original Text A (line 5): C++111410刷\n",
      "Best Match for Text A (line 5): C++1114コア言語10刷突破!C++入門書のロングセラー!!~.マイナビ\n",
      "Highest Jaccard Coefficient: 0.2069\n",
      "\n",
      "Original Text A (line 6): CUDACCUDAの機能・手法をプロフェッショナルプログラミング網羅的に解説!\n",
      "Best Match for Text A (line 6): CUDACプロフェッショナルプログラミングCUDAの機能・手法を網羅的に解説!\n",
      "Highest Jaccard Coefficient: 1.0000\n",
      "\n",
      "Original Text A (line 7): HOTELE言語実装パターンコンパイラ技術によるテキスト処理か言語実装までらTem\n",
      "Best Match for Text A (line 7): 言語実装パターンコンパイラ技術によるテキスト処理から言語実装までTerence Parr著中田育男監訳伊藤真浩訳O'Reilly\n",
      "Highest Jaccard Coefficient: 0.5273\n",
      "\n",
      "Original Text A (line 8): 詳解OpenCV3コンピュータビジョンライブラリを使った画像処理・認識永松G\n",
      "Best Match for Text A (line 8): 詳解OpenCV3AdrianKaehlerGaryBradski松田晃一、小沼千絵著永田雅人、花形理訳O'REILLY\n",
      "Highest Jaccard Coefficient: 0.1912\n",
      "\n",
      "Original Text A (line 9): リスク評価と危機管理ネットワークバ\n",
      "Best Match for Text A (line 9): 実践ネットワークセキュリティ監査リスク評価と危機管理ChrisMcNab著鍋島公章監訳(株)ネットワークバリューコンポネンツ訳O'REILLY\n",
      "Highest Jaccard Coefficient: 0.2909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def jaccard_coefficient(s1, s2):\n",
    "    set1 = set(s1)\n",
    "    set2 = set(s2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = jaccard_coefficient(text_a.strip(), text_b.strip())\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "\n",
    "        print(f\"Original Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        print(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\")\n",
    "        print(f\"Highest Jaccard Coefficient: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "416f1222-e91f-434b-bea1-228250c67966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "    output_file = \"jaccard_similarity.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for index_a, text_a in enumerate(lines_a):\n",
    "            for index_b, text_b in enumerate(lines_b):\n",
    "                similarity = jaccard_coefficient(text_a.strip(), text_b.strip())\n",
    "\n",
    "                output.write(f\"Text A (line {index_a + 1}): {text_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {index_b + 1}): {text_b.strip()}\\n\")\n",
    "                output.write(f\"Jaccard Coefficient: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "e09ee634-7830-4b7a-b93f-a49c73cd1931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text A (line 1): 新明解C言語入門編柴田\n",
      "Best Match for Text A (line 1): 新・明解C言語入門編柴田望洋SBCreative\n",
      "Highest Jaccard Coefficient: 0.5000\n",
      "\n",
      "Original Text A (line 2): 解きながら学ぶC言明解きながら学ぶC言語柴田望\n",
      "Best Match for Text A (line 2): 解きながら学ぶC言語柴田望洋[監修・著]赤尾浩・肘井信一・高木宏典[著]SBCreative\n",
      "Highest Jaccard Coefficient: 0.3250\n",
      "\n",
      "Original Text A (line 3): プログラミングROSPythonによるロボットアプリケーション開発MorganQuigleyBrianGerkeyWilliamD.Smart\n",
      "Best Match for Text A (line 3): プログラミングROSPythonによるロボットアプリケーション開発MorganQuigleyBrianGerkeyWilliamD.Smart河田卓志監訳松田晃一、福地正樹、由谷哲夫訳O'REILLY\n",
      "Highest Jaccard Coefficient: 0.6618\n",
      "\n",
      "Original Text A (line 4): KINECTforWindowsSDKプログラミングC++編\n",
      "Best Match for Text A (line 4): KINECTforWindowsSDKプログラミングC++編株式会社ゲッシュ中村薰齋藤俊太宮城英人〈著>システム\n",
      "Highest Jaccard Coefficient: 0.5000\n",
      "\n",
      "Original Text A (line 5): C++111410刷\n",
      "Best Match for Text A (line 5): C++1114コア言語10刷突破!C++入門書のロングセラー!!~.マイナビ\n",
      "Highest Jaccard Coefficient: 0.2069\n",
      "\n",
      "Original Text A (line 6): CUDACCUDAの機能・手法をプロフェッショナルプログラミング網羅的に解説!\n",
      "Best Match for Text A (line 6): CUDACプロフェッショナルプログラミングCUDAの機能・手法を網羅的に解説!\n",
      "Highest Jaccard Coefficient: 1.0000\n",
      "\n",
      "Original Text A (line 7): HOTELE言語実装パターンコンパイラ技術によるテキスト処理か言語実装までらTem\n",
      "Best Match for Text A (line 7): 言語実装パターンコンパイラ技術によるテキスト処理から言語実装までTerence Parr著中田育男監訳伊藤真浩訳O'Reilly\n",
      "Highest Jaccard Coefficient: 0.5273\n",
      "\n",
      "Original Text A (line 8): 詳解OpenCV3コンピュータビジョンライブラリを使った画像処理・認識永松G\n",
      "Best Match for Text A (line 8): 詳解OpenCV3AdrianKaehlerGaryBradski松田晃一、小沼千絵著永田雅人、花形理訳O'REILLY\n",
      "Highest Jaccard Coefficient: 0.1912\n",
      "\n",
      "Original Text A (line 9): リスク評価と危機管理ネットワークバ\n",
      "Best Match for Text A (line 9): 実践ネットワークセキュリティ監査リスク評価と危機管理ChrisMcNab著鍋島公章監訳(株)ネットワークバリューコンポネンツ訳O'REILLY\n",
      "Highest Jaccard Coefficient: 0.2909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def jaccard_coefficient(s1, s2):\n",
    "    set1 = set(s1)\n",
    "    set2 = set(s2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        # 空白の行をスキップ\n",
    "        if not text_a.strip():\n",
    "            continue\n",
    "\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = jaccard_coefficient(text_a.strip(), text_b.strip())\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "\n",
    "        print(f\"Original Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        \n",
    "        if best_match is not None:\n",
    "            print(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\")\n",
    "            print(f\"Highest Jaccard Coefficient: {max_similarity:.4f}\\n\")\n",
    "        else:\n",
    "            print(\"No matching text found.\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138d09b-6749-46c9-a90d-7e1e3ef7af2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "localGPU",
   "language": "python",
   "name": "localgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
