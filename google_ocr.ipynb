{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41c22aa-d628-4037-8f16-e68d16e05e54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Start Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1c2e17-ea96-45fe-b65e-fb272c1f2851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd46a61e-888d-40f4-ae2a-1e6458c4455b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T14:53:53.138703Z",
     "start_time": "2023-05-23T14:53:53.097171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\covid\\text_recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992b6658-efd2-41b3-a71f-3f20fb8b97ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T14:53:53.138703Z",
     "start_time": "2023-05-23T14:53:53.097171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=177107319826-i8oj1jnq3najvtvm0prpb18ncuipamef.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A50257%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.file&state=wT5kf4BCzvkWlLjOrN5S9Dgs8MojxQ&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "MIME_TYPE = 'application/vnd.google-apps.document'\n",
    "APPLICATION_NAME = 'ipa-google-drive-api-client'\n",
    "\n",
    "def get_service():\n",
    "\n",
    "    # credentialの取得\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'google-drive-api.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "        \n",
    "    # serviceの取得\n",
    "    service = build('drive', 'v3', credentials=creds) \n",
    "    \n",
    "    return service\n",
    "\n",
    "def read_ocr(service, input_file, lang='jp'):\n",
    "    # ファイルのアップロード\n",
    "\n",
    "    # ローカルファイルの定義\n",
    "    media_body = MediaFileUpload(input_file, mimetype=MIME_TYPE, resumable=True)\n",
    "\n",
    "    # Google Drive上のファイル名\n",
    "    newfile = 'output.pdf'\n",
    "\n",
    "    body = {\n",
    "        'name': newfile,\n",
    "        'mimeType': MIME_TYPE\n",
    "    }\n",
    "\n",
    "    # 　creat関数でファイルアップロード実行\n",
    "    # 同時にOCR読み取りも行う\n",
    "    output = service.files().create(\n",
    "        body=body,\n",
    "        media_body=media_body,\n",
    "        # ここで読み込み先言語の指定を行う\n",
    "        ocrLanguage=lang,\n",
    "    ).execute()\n",
    "\n",
    "    # テキストファイルのダウンロード\n",
    "\n",
    "    # リクエストオブジェクト生成\n",
    "    request = service.files().export_media(\n",
    "        fileId=output['id'],\n",
    "        mimeType=\"text/plain\"\n",
    "    )\n",
    "    output_path = 'output.txt'\n",
    "\n",
    "    with open(output_path, 'a') as f:\n",
    "        fh = io.FileIO(output_path, \"wb\")\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "\n",
    "        service.files().delete(fileId=output['id']).execute()\n",
    "    \n",
    "        # テキストの取得\n",
    "    with open(output_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 読み取り結果のリストを返す\n",
    "    return lines[1:]\n",
    "\n",
    "\n",
    "service = get_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94045e0-35ba-4a5d-8254-d9a671c7339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_file(text_file):\n",
    "    output_dir = \"C:/Users/covid/text_recognition/output\"\n",
    "    if os.path.exists(output_dir):\n",
    "        file_list = [f for f in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, f))]\n",
    "        for file_name in file_list:\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "            os.remove(file_path)\n",
    "    else:\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with open(text_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        lines = sorted(lines, key=lambda line: float(line.split()[1]))\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            values = line.split()\n",
    "\n",
    "            if len(values) == 5:\n",
    "                object_class = values[0]\n",
    "                a = float(values[1])\n",
    "                b = float(values[2])\n",
    "                c = float(values[3])\n",
    "                d = float(values[4])\n",
    "\n",
    "                # Calculate coordinates and dimensions\n",
    "                x_center = int(wid * a)\n",
    "                y_center = int(hei * b)\n",
    "                width = int(wid * c)\n",
    "                height = int(hei * d)\n",
    "\n",
    "                x_min = x_center - width // 2\n",
    "                y_min = y_center - height // 2\n",
    "                x_max = x_center + width // 2\n",
    "                y_max = y_center + height // 2\n",
    "\n",
    "                output_filename = os.path.join(output_dir, f'book{i+1}.jpg')\n",
    "                index = 1\n",
    "                while os.path.exists(output_filename):\n",
    "                    output_filename = os.path.join(output_dir, f'book{i+1}_{index}.jpg')\n",
    "                    index += 1\n",
    "\n",
    "                # Crop and save the image\n",
    "                cropped = image.crop((x_min, y_min, x_max, y_max))\n",
    "                cropped.save(output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0464a813-edff-46e4-bc2f-c42e3b828af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# カメラの読込み\n",
    "# 内蔵カメラがある場合、下記引数の数字を変更する必要あり\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 動画終了まで、1フレームずつ読み込んで表示する。\n",
    "while(cap.isOpened()):\n",
    "    # 1フレーム毎　読込み\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # GUIに表示\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "    # qキーが押されたら途中終了\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 終了処理\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bde91463-c141-461e-9d3d-af02f4c1a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable list\n",
    "# ディレクトリのパス\n",
    "directory_path = \"C:/Users/covid/text_recognition/yolov7/runs/detect/\"\n",
    "# 画像ファイルの相対パスを指定\n",
    "image_relative_path = \"input.png\"\n",
    "# テキストファイルの相対パスを指定\n",
    "text_file_relative_path = \"labels/input.txt\"\n",
    "\n",
    "out_path = 'C:/Users/covid/text_recognition/output'\n",
    "output_file = \"C:/Users/covid/text_recognition/output_results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf8b8d54-f2f9-4d9d-b344-002b96254b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if ret:#カメラと本棚の距離→0.6m\n",
    "    x = 0  # トリミングの左上のX座標\n",
    "    y = 90  # トリミングの左上のY座標\n",
    "    width = 640  # トリミングする幅\n",
    "    height = 200  # トリミングする高さ\n",
    "    \n",
    "    cropped_frame = frame[y:y+height, x:x+width]\n",
    "\n",
    "    cv2.imwrite(\"C:/Users/covid/text_recognition/yolov7/input.png\", cropped_frame)\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbdca0-abe2-41e8-ab29-9c0d0a553d1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b9ce244-8ea8-462f-b9a1-97f0c7b7b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "cv2.imwrite(\"C:/Users/covid/text_recognition/yolov7/input.png\",frame)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddd81928-34a6-4223-9e45-7c8283efac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\\yolov7\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\covid\\text_recognition\\yolov7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47c2ccd2-7059-4b24-967a-3b588652eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ内のサブディレクトリのリストを取得\n",
    "subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "# サブディレクトリの中で一番新しいものを取得\n",
    "newest_subdirectory = max(subdirectories, key=lambda d: os.path.getctime(os.path.join(directory_path, d)))\n",
    "\n",
    "# 最新のサブディレクトリのパスを作成\n",
    "newest_subdirectory_path = os.path.join(directory_path, newest_subdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3504fcd-93e7-427a-944d-161d4f3b56fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['yolov7-e6e.pt'], source='C:/Users/covid/text_recognition/yolov7/input.png', img_size=1280, conf_thres=0.25, iou_thres=0.45, device='0', view_img=False, save_txt=True, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
      "Fusing layers... \n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "19 books, Done. (35.0ms) Inference, (44.0ms) NMS\n",
      " The image with the result is saved in: runs\\detect\\exp18\\input.png\n",
      "Done. (0.556s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  v0.1-126-g84932d7 torch 2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "Model Summary: 792 layers, 151687420 parameters, 817020 gradients\n",
      "C:\\Users\\covid\\anaconda3\\envs\\localGPU\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source C:/Users/covid/text_recognition/yolov7/input.png --weights yolov7-e6e.pt --conf 0.25 --img-size 1280 --device 0 --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1820bb9-6774-4ac4-8085-ab3c7f8ec3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ内のサブディレクトリのリストを取得\n",
    "subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "# サブディレクトリの中で一番新しいものを取得\n",
    "newest_subdirectory = max(subdirectories, key=lambda d: os.path.getctime(os.path.join(directory_path, d)))\n",
    "\n",
    "# 最新のサブディレクトリのパスを作成\n",
    "newest_subdirectory_path = os.path.join(directory_path, newest_subdirectory)\n",
    "\n",
    "# 新しいディレクトリに移動\n",
    "os.chdir(newest_subdirectory_path)\n",
    "\n",
    "# 画像ファイルの絶対パスを作成\n",
    "image_absolute_path = os.path.join(newest_subdirectory_path, image_relative_path)\n",
    "# テキストファイルの絶対パスを作成\n",
    "text_file_absolute_path = os.path.join(newest_subdirectory_path, text_file_relative_path)\n",
    "\n",
    "# 画像をImageクラスのインスタンスに読み込む\n",
    "image = Image.open(image_absolute_path)\n",
    "# テキストファイルを読み込む\n",
    "with open(text_file_absolute_path, 'r') as file:\n",
    "    text_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e30fd2d9-71f2-47b1-a602-2b1d9b7c14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text file\n",
    "wid,hei = image.size\n",
    "process_text_file(text_file_absolute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "999c5e72-1c01-446e-bec0-a6bc50775a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output corresponding to list format\n",
    "if __name__ == '__main__':\n",
    "    output_list = []\n",
    "\n",
    "    file_list = [filename for filename in os.listdir(out_path) if filename.endswith('.jpg')]\n",
    "    file_list.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "    for filename in file_list:\n",
    "        input_file = os.path.join(out_path, filename)\n",
    "        output = read_ocr(service, input_file, 'ja')\n",
    "\n",
    "        # 不要な文字（スペースとバックスラッシュ）を除去して一つの文字列に結合する\n",
    "        cleaned_output = ''.join(line.strip().replace(' ', '').replace('/', '').replace('\\n', '').replace('\\\\', '') for line in output)\n",
    "\n",
    "        # 結果をリストに追加\n",
    "        output_list.append(cleaned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4e40376-a25b-4581-beb2-9e987664e456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:/Users/covid/text_recognition/output_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the results to the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for result in output_list:\n",
    "            file.write(result + '\\n')\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a8433c-74fa-4409-9410-da659b44c5d4",
   "metadata": {},
   "source": [
    "## Compare Methods of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e791e-ffb3-4710-89d3-d281d8017ba6",
   "metadata": {},
   "source": [
    "### Different.SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b25da00-05b8-4cb9-9cbd-fd60b655e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\\\Users\\\\covid\\\\text_recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "701f522b-4abb-4bd9-a9d1-53415a4b2590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text A (line 1): 統計のための行列代数DAハーヴィル:8\n",
      "Best Match in Text B (line 1): 統計のための行列代数上D・A・ハーヴィル著伊里正夫監訳丸善\n",
      "Highest Similarity Ratio: 0.7200\n",
      "\n",
      "Text A (line 2): フィッシャー研究者のための統計的方法RAF・\n",
      "Best Match in Text B (line 3): R・A・フィッシャー研究者のための統計的方法R・A・Fisher[著]遠藤健児・鍋谷清治[訳]D908\n",
      "Highest Similarity Ratio: 0.6133\n",
      "\n",
      "Text A (line 3): 力学系\n",
      "Best Match in Text B (line 4): DYNAMICALSYSTEMS力学系上C・ロビンソン著國府寛司・柴山健伸岡宏枝訳\n",
      "Highest Similarity Ratio: 0.1739\n",
      "\n",
      "Text A (line 4): ポイント線形代数四ツ\n",
      "Best Match in Text B (line 5): キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Similarity Ratio: 0.6286\n",
      "\n",
      "Text A (line 5): a\n",
      "Best Match in Text B (line 19): 理科系の作文技術木下是雄著中公新書624\n",
      "Highest Similarity Ratio: 0.0870\n",
      "\n",
      "Text A (line 6): キーポイント線形代数四ツ谷\n",
      "Best Match in Text B (line 5): キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Similarity Ratio: 0.7368\n",
      "\n",
      "Text A (line 7): シリーズ数理統計学の基礎尾畑伸明(\n",
      "Best Match in Text B (line 8): クロスセクショナル統計シリーズ1数理統計学の基礎尾畑伸明[著]\n",
      "Highest Similarity Ratio: 0.6800\n",
      "\n",
      "Text A (line 8): a\n",
      "Best Match in Text B (line 19): 理科系の作文技術木下是雄著中公新書624\n",
      "Highest Similarity Ratio: 0.0870\n",
      "\n",
      "Text A (line 9): 入門ベイズ統計松原望\n",
      "Best Match in Text B (line 10): 入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "Highest Similarity Ratio: 0.5946\n",
      "\n",
      "Text A (line 10): ベイズ統計学\n",
      "Best Match in Text B (line 10): 入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "Highest Similarity Ratio: 0.3636\n",
      "\n",
      "Text A (line 11): 人工生命ENER\n",
      "Best Match in Text B (line 12): ArtificialLife人工生命改定2版バイオインフォマティクスシリーズ有田隆也[著]医学出版\n",
      "Highest Similarity Ratio: 0.1695\n",
      "\n",
      "Text A (line 12): 一一'線型代数入門市藤正接著\n",
      "Best Match in Text B (line 13): 数学基礎1線形代数入門斎藤正彦東京大学出版会\n",
      "Highest Similarity Ratio: 0.4211\n",
      "\n",
      "Text A (line 13): 解析演習打由无无+青水英里全子兒。因本相大\n",
      "Best Match in Text B (line 14): 数学基礎7解析演習杉浦光夫・清水英男金子晃・岡本和夫著東京大学出版会\n",
      "Highest Similarity Ratio: 0.3509\n",
      "\n",
      "Text A (line 14): *嗎?解析入門I\n",
      "Best Match in Text B (line 15): 数学基礎2解析入門Ⅰ杉浦光夫著東京大学出版会\n",
      "Highest Similarity Ratio: 0.3125\n",
      "\n",
      "Text A (line 15): StructureandInterpretationofComputerProgramsSecondEditionAbelsonandSussmanW\n",
      "Best Match in Text B (line 16): Structure and Interpretation of Computer Programs Second Edition Abelson and Sussman\n",
      "Highest Similarity Ratio: 0.9317\n",
      "\n",
      "Text A (line 16): 微生物の力学系ルスミス竹内ポール・ウォルトマン(著)(日本\n",
      "Best Match in Text B (line 17): 微生物の力学系ケモスタット理論を通してハル・スミス＆ポール・ウォルトマン[著]竹内康博[監訳]日本評議院\n",
      "Highest Similarity Ratio: 0.6024\n",
      "\n",
      "Text A (line 17): デクステリティ巧みさとそのニコライ・ベルシュタインK\n",
      "Best Match in Text B (line 18): デクステリティ巧みさとその発達ニコライ・A・ベルンシュタイン著工藤和俊訳佐々木正人監訳金子書房\n",
      "Highest Similarity Ratio: 0.6933\n",
      "\n",
      "Text A (line 18): 理科系の作文技術\n",
      "Best Match in Text B (line 19): 理科系の作文技術木下是雄著中公新書624\n",
      "Highest Similarity Ratio: 0.5517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "        best_match_text_b = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = difflib.SequenceMatcher(None, text_a, text_b).ratio()\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "                best_match_text_b = text_b\n",
    "\n",
    "        print(f\"Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        print(f\"Best Match in Text B (line {lines_b.index(best_match) + 1}): {best_match.strip()}\")\n",
    "        print(f\"Highest Similarity Ratio: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e727c425-5ef0-4898-a436-836db1771d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "    output_file = \"output_similarity.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for index_a, text_a in enumerate(lines_a):\n",
    "            for index_b, text_b in enumerate(lines_b):\n",
    "                similarity = difflib.SequenceMatcher(None, text_a, text_b).ratio()\n",
    "\n",
    "                output.write(f\"Text A (line {index_a + 1}): {text_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {index_b + 1}): {text_b.strip()}\\n\")\n",
    "                output.write(f\"Similarity Ratio: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7afaa8-03cb-41ba-9122-46a2d0c15d05",
   "metadata": {},
   "source": [
    "### Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b026ed89-2870-4469-9be3-05b8818d9871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text A (line 1): 統計のための行列代数DAハーヴィル:8\n",
      "Best Match for Text A (line 1): 統計のための行列代数上D・A・ハーヴィル著伊里正夫監訳丸善\n",
      "Highest Similarity Ratio: 0.7083\n",
      "\n",
      "Original Text A (line 2): フィッシャー研究者のための統計的方法RAF・\n",
      "Best Match for Text A (line 2): R・A・フィッシャー研究者のための統計的方法R・A・Fisher[著]遠藤健児・鍋谷清治[訳]D908\n",
      "Highest Similarity Ratio: 0.6027\n",
      "\n",
      "Original Text A (line 3): 力学系\n",
      "Best Match for Text A (line 3): DYNAMICALSYSTEMS力学系上C・ロビンソン著國府寛司・柴山健伸岡宏枝訳\n",
      "Highest Similarity Ratio: 0.1364\n",
      "\n",
      "Original Text A (line 4): ポイント線形代数四ツ\n",
      "Best Match for Text A (line 4): キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Similarity Ratio: 0.6061\n",
      "\n",
      "Original Text A (line 5): a\n",
      "Best Match for Text A (line 5): ArtificialLife人工生命改定2版バイオインフォマティクスシリーズ有田隆也[著]医学出版\n",
      "Highest Similarity Ratio: 0.0400\n",
      "\n",
      "Original Text A (line 6): キーポイント線形代数四ツ谷\n",
      "Best Match for Text A (line 6): キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Similarity Ratio: 0.7222\n",
      "\n",
      "Original Text A (line 7): シリーズ数理統計学の基礎尾畑伸明(\n",
      "Best Match for Text A (line 7): クロスセクショナル統計シリーズ1数理統計学の基礎尾畑伸明[著]\n",
      "Highest Similarity Ratio: 0.6667\n",
      "\n",
      "Original Text A (line 8): a\n",
      "Best Match for Text A (line 8): ArtificialLife人工生命改定2版バイオインフォマティクスシリーズ有田隆也[著]医学出版\n",
      "Highest Similarity Ratio: 0.0400\n",
      "\n",
      "Original Text A (line 9): 入門ベイズ統計松原望\n",
      "Best Match for Text A (line 9): 入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "Highest Similarity Ratio: 0.5714\n",
      "\n",
      "Original Text A (line 10): ベイズ統計学\n",
      "Best Match for Text A (line 10): 入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "Highest Similarity Ratio: 0.3226\n",
      "\n",
      "Original Text A (line 11): 人工生命ENER\n",
      "Best Match for Text A (line 11): ArtificialLife人工生命改定2版バイオインフォマティクスシリーズ有田隆也[著]医学出版\n",
      "Highest Similarity Ratio: 0.1404\n",
      "\n",
      "Original Text A (line 12): 一一'線型代数入門市藤正接著\n",
      "Best Match for Text A (line 12): 数学基礎1線形代数入門斎藤正彦東京大学出版会\n",
      "Highest Similarity Ratio: 0.3889\n",
      "\n",
      "Original Text A (line 13): 解析演習打由无无+青水英里全子兒。因本相大\n",
      "Best Match for Text A (line 13): 数学基礎7解析演習杉浦光夫・清水英男金子晃・岡本和夫著東京大学出版会\n",
      "Highest Similarity Ratio: 0.3273\n",
      "\n",
      "Original Text A (line 14): *嗎?解析入門I\n",
      "Best Match for Text A (line 14): 数学基礎2解析入門Ⅰ杉浦光夫著東京大学出版会\n",
      "Highest Similarity Ratio: 0.2667\n",
      "\n",
      "Original Text A (line 15): StructureandInterpretationofComputerProgramsSecondEditionAbelsonandSussmanW\n",
      "Best Match for Text A (line 15): Structure and Interpretation of Computer Programs Second Edition Abelson and Sussman\n",
      "Highest Similarity Ratio: 0.9308\n",
      "\n",
      "Original Text A (line 16): 微生物の力学系ルスミス竹内ポール・ウォルトマン(著)(日本\n",
      "Best Match for Text A (line 16): 微生物の力学系ケモスタット理論を通してハル・スミス＆ポール・ウォルトマン[著]竹内康博[監訳]日本評議院\n",
      "Highest Similarity Ratio: 0.5926\n",
      "\n",
      "Original Text A (line 17): デクステリティ巧みさとそのニコライ・ベルシュタインK\n",
      "Best Match for Text A (line 17): デクステリティ巧みさとその発達ニコライ・A・ベルンシュタイン著工藤和俊訳佐々木正人監訳金子書房\n",
      "Highest Similarity Ratio: 0.6849\n",
      "\n",
      "Original Text A (line 18): 理科系の作文技術\n",
      "Best Match for Text A (line 18): 理科系の作文技術木下是雄著中公新書624\n",
      "Highest Similarity Ratio: 0.5714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = Levenshtein.ratio(text_a.strip(), text_b.strip())\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "\n",
    "        print(f\"Original Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        print(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\")\n",
    "        print(f\"Highest Similarity Ratio: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9b1a02a-d969-41cc-9259-99c68cd0197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "    output_file = \"levenshtein_similarity.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for index_a, text_a in enumerate(lines_a):\n",
    "            max_similarity = 0.0\n",
    "            best_match = None\n",
    "\n",
    "            for index_b, text_b in enumerate(lines_b):\n",
    "                similarity = Levenshtein.ratio(text_a.strip(), text_b.strip())\n",
    "\n",
    "                output.write(f\"Text A (line {index_a + 1}): {text_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {index_b + 1}): {text_b.strip()}\\n\")\n",
    "                output.write(f\"Similarity Ratio: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    best_match = text_b\n",
    "\n",
    "            output.write(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\\n\")\n",
    "            output.write(f\"Highest Similarity Ratio: {max_similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10ac69-6023-489f-b011-da3a9cdf0fbb",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cec8f9cc-613e-4429-9362-5e3806445fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text A (line 1): 統計のための行列代数DAハーヴィル:8\n",
      "Best Match for Text A (line 1): 統計のための行列代数上D・A・ハーヴィル著伊里正夫監訳丸善\n",
      "Highest Jaccard Coefficient: 0.5517\n",
      "\n",
      "Original Text A (line 2): フィッシャー研究者のための統計的方法RAF・\n",
      "Best Match for Text A (line 2): R・A・フィッシャー研究者のための統計的方法R・A・Fisher[著]遠藤健児・鍋谷清治[訳]D908\n",
      "Highest Jaccard Coefficient: 0.5000\n",
      "\n",
      "Original Text A (line 3): 力学系\n",
      "Best Match for Text A (line 3): DYNAMICALSYSTEMS力学系上C・ロビンソン著國府寛司・柴山健伸岡宏枝訳\n",
      "Highest Jaccard Coefficient: 0.0909\n",
      "\n",
      "Original Text A (line 4): ポイント線形代数四ツ\n",
      "Best Match for Text A (line 4): キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Jaccard Coefficient: 0.4348\n",
      "\n",
      "Original Text A (line 5): a\n",
      "Best Match for Text A (line 5): Structure and Interpretation of Computer Programs Second Edition Abelson and Sussman\n",
      "Highest Jaccard Coefficient: 0.0417\n",
      "\n",
      "Original Text A (line 6): キーポイント線形代数四ツ谷\n",
      "Best Match for Text A (line 6): キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Jaccard Coefficient: 0.5652\n",
      "\n",
      "Original Text A (line 7): シリーズ数理統計学の基礎尾畑伸明(\n",
      "Best Match for Text A (line 7): クロスセクショナル統計シリーズ1数理統計学の基礎尾畑伸明[著]\n",
      "Highest Jaccard Coefficient: 0.5714\n",
      "\n",
      "Original Text A (line 8): a\n",
      "Best Match for Text A (line 8): Structure and Interpretation of Computer Programs Second Edition Abelson and Sussman\n",
      "Highest Jaccard Coefficient: 0.0417\n",
      "\n",
      "Original Text A (line 9): 入門ベイズ統計松原望\n",
      "Best Match for Text A (line 9): 入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "Highest Jaccard Coefficient: 0.4000\n",
      "\n",
      "Original Text A (line 10): ベイズ統計学\n",
      "Best Match for Text A (line 10): やさしく知りたい先端科学シリーズ1ベイズ統計学松原望創元社創元社\n",
      "Highest Jaccard Coefficient: 0.2222\n",
      "\n",
      "Original Text A (line 11): 人工生命ENER\n",
      "Best Match for Text A (line 11): ArtificialLife人工生命改定2版バイオインフォマティクスシリーズ有田隆也[著]医学出版\n",
      "Highest Jaccard Coefficient: 0.0870\n",
      "\n",
      "Original Text A (line 12): 一一'線型代数入門市藤正接著\n",
      "Best Match for Text A (line 12): 数学基礎1線形代数入門斎藤正彦東京大学出版会\n",
      "Highest Jaccard Coefficient: 0.2692\n",
      "\n",
      "Original Text A (line 13): 解析演習打由无无+青水英里全子兒。因本相大\n",
      "Best Match for Text A (line 13): 数学基礎7解析演習杉浦光夫・清水英男金子晃・岡本和夫著東京大学出版会\n",
      "Highest Jaccard Coefficient: 0.2143\n",
      "\n",
      "Original Text A (line 14): *嗎?解析入門I\n",
      "Best Match for Text A (line 14): 数学基礎2解析入門Ⅰ杉浦光夫著東京大学出版会\n",
      "Highest Jaccard Coefficient: 0.1600\n",
      "\n",
      "Original Text A (line 15): StructureandInterpretationofComputerProgramsSecondEditionAbelsonandSussmanW\n",
      "Best Match for Text A (line 15): Structure and Interpretation of Computer Programs Second Edition Abelson and Sussman\n",
      "Highest Jaccard Coefficient: 0.9200\n",
      "\n",
      "Original Text A (line 16): 微生物の力学系ルスミス竹内ポール・ウォルトマン(著)(日本\n",
      "Best Match for Text A (line 16): 微生物の力学系ケモスタット理論を通してハル・スミス＆ポール・ウォルトマン[著]竹内康博[監訳]日本評議院\n",
      "Highest Jaccard Coefficient: 0.5000\n",
      "\n",
      "Original Text A (line 17): デクステリティ巧みさとそのニコライ・ベルシュタインK\n",
      "Best Match for Text A (line 17): デクステリティ巧みさとその発達ニコライ・A・ベルンシュタイン著工藤和俊訳佐々木正人監訳金子書房\n",
      "Highest Jaccard Coefficient: 0.5349\n",
      "\n",
      "Original Text A (line 18): 理科系の作文技術\n",
      "Best Match for Text A (line 18): 理科系の作文技術木下是雄著中公新書624\n",
      "Highest Jaccard Coefficient: 0.4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def jaccard_coefficient(s1, s2):\n",
    "    set1 = set(s1)\n",
    "    set2 = set(s2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    for index_a, text_a in enumerate(lines_a):\n",
    "        max_similarity = 0.0\n",
    "        best_match = None\n",
    "\n",
    "        for index_b, text_b in enumerate(lines_b):\n",
    "            similarity = jaccard_coefficient(text_a.strip(), text_b.strip())\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_match = text_b\n",
    "\n",
    "        print(f\"Original Text A (line {index_a + 1}): {text_a.strip()}\")\n",
    "        print(f\"Best Match for Text A (line {index_a + 1}): {best_match.strip()}\")\n",
    "        print(f\"Highest Jaccard Coefficient: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "416f1222-e91f-434b-bea1-228250c67966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coefficient(s1, s2):\n",
    "    set1 = set(s1)\n",
    "    set2 = set(s2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "    output_file = \"jaccard_similarity.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for index_a, text_a in enumerate(lines_a):\n",
    "            for index_b, text_b in enumerate(lines_b):\n",
    "                similarity = jaccard_coefficient(text_a.strip(), text_b.strip())\n",
    "\n",
    "                output.write(f\"Text A (line {index_a + 1}): {text_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {index_b + 1}): {text_b.strip()}\\n\")\n",
    "                output.write(f\"Jaccard Coefficient: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "351d00e9-c464-4b32-b490-7686a99c3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_cosine_similarity(texts):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_sim\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    cosine_sim = calculate_cosine_similarity(lines_a + lines_b)\n",
    "\n",
    "    output_file = \"cosine_similarity_results.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for i, line_a in enumerate(lines_a):\n",
    "            for j, line_b in enumerate(lines_b):\n",
    "                similarity = cosine_sim[i][j]\n",
    "                output.write(f\"Text A (line {i + 1}): {line_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {j + 1}): {line_b.strip()}\\n\")\n",
    "                output.write(f\"Cosine Similarity: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f35f20-4530-4ddb-a9b7-9f8c29dd5957",
   "metadata": {},
   "source": [
    "### n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efa820ea-4667-433a-b157-d3bb87a21d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全文出力\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_ngram_similarity(texts):\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_sim\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    cosine_sim = calculate_ngram_similarity(lines_a + lines_b)\n",
    "\n",
    "    output_file = \"ngram_similarity_results.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for i, line_a in enumerate(lines_a):\n",
    "            for j, similarity in enumerate(cosine_sim[i][len(lines_a):]):\n",
    "                output.write(f\"Text A (line {i + 1}): {line_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {j + 1}): {lines_b[j].strip()}\\n\")\n",
    "                output.write(f\"N-gram Similarity: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d33791a5-ee62-4a44-a4d8-421ffc03030d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text A (line 1): 統計のための行列代数DAハーヴィル:8\n",
      "Best Match for Text A: 統計のための行列代数上D・A・ハーヴィル著伊里正夫監訳丸善\n",
      "Highest N-gram Similarity: 0.4900\n",
      "\n",
      "Text A (line 2): フィッシャー研究者のための統計的方法RAF・\n",
      "Best Match for Text A: R・A・フィッシャー研究者のための統計的方法R・A・Fisher[著]遠藤健児・鍋谷清治[訳]D908\n",
      "Highest N-gram Similarity: 0.5048\n",
      "\n",
      "Text A (line 3): 力学系\n",
      "Best Match for Text A: DYNAMICALSYSTEMS力学系上C・ロビンソン著國府寛司・柴山健伸岡宏枝訳\n",
      "Highest N-gram Similarity: 0.1118\n",
      "\n",
      "Text A (line 4): ポイント線形代数四ツ\n",
      "Best Match for Text A: キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest N-gram Similarity: 0.4264\n",
      "\n",
      "Text A (line 6): キーポイント線形代数四ツ谷\n",
      "Best Match for Text A: キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest N-gram Similarity: 0.5539\n",
      "\n",
      "Text A (line 7): シリーズ数理統計学の基礎尾畑伸明(\n",
      "Best Match for Text A: クロスセクショナル統計シリーズ1数理統計学の基礎尾畑伸明[著]\n",
      "Highest N-gram Similarity: 0.5477\n",
      "\n",
      "Text A (line 9): 入門ベイズ統計松原望\n",
      "Best Match for Text A: 入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "Highest N-gram Similarity: 0.4082\n",
      "\n",
      "Text A (line 10): ベイズ統計学\n",
      "Best Match for Text A: やさしく知りたい先端科学シリーズ1ベイズ統計学松原望創元社創元社\n",
      "Highest N-gram Similarity: 0.3114\n",
      "\n",
      "Text A (line 11): 人工生命ENER\n",
      "Best Match for Text A: ArtificialLife人工生命改定2版バイオインフォマティクスシリーズ有田隆也[著]医学出版\n",
      "Highest N-gram Similarity: 0.1091\n",
      "\n",
      "Text A (line 12): 一一'線型代数入門市藤正接著\n",
      "Best Match for Text A: 数学基礎1線形代数入門斎藤正彦東京大学出版会\n",
      "Highest N-gram Similarity: 0.1210\n",
      "\n",
      "Text A (line 13): 解析演習打由无无+青水英里全子兒。因本相大\n",
      "Best Match for Text A: 数学基礎7解析演習杉浦光夫・清水英男金子晃・岡本和夫著東京大学出版会\n",
      "Highest N-gram Similarity: 0.0778\n",
      "\n",
      "Text A (line 14): *嗎?解析入門I\n",
      "Best Match for Text A: 数学基礎2解析入門Ⅰ杉浦光夫著東京大学出版会\n",
      "Highest N-gram Similarity: 0.1650\n",
      "\n",
      "Text A (line 15): StructureandInterpretationofComputerProgramsSecondEditionAbelsonandSussmanW\n",
      "Best Match for Text A: Structure and Interpretation of Computer Programs Second Edition Abelson and Sussman\n",
      "Highest N-gram Similarity: 0.6389\n",
      "\n",
      "Text A (line 16): 微生物の力学系ルスミス竹内ポール・ウォルトマン(著)(日本\n",
      "Best Match for Text A: 微生物の力学系ケモスタット理論を通してハル・スミス＆ポール・ウォルトマン[著]竹内康博[監訳]日本評議院\n",
      "Highest N-gram Similarity: 0.3705\n",
      "\n",
      "Text A (line 17): デクステリティ巧みさとそのニコライ・ベルシュタインK\n",
      "Best Match for Text A: デクステリティ巧みさとその発達ニコライ・A・ベルンシュタイン著工藤和俊訳佐々木正人監訳金子書房\n",
      "Highest N-gram Similarity: 0.5308\n",
      "\n",
      "Text A (line 18): 理科系の作文技術\n",
      "Best Match for Text A: 理科系の作文技術木下是雄著中公新書624\n",
      "Highest N-gram Similarity: 0.5620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#最大値出力\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_ngram_similarity(texts):\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_sim\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    cosine_sim = calculate_ngram_similarity(lines_a + lines_b)\n",
    "\n",
    "    output_file = \"ngram_similarity_results.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for i, line_a in enumerate(lines_a):\n",
    "            max_similarity = 0.0\n",
    "            best_match = None\n",
    "            best_match_index = -1\n",
    "            for j, similarity in enumerate(cosine_sim[i][len(lines_a):]):\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    best_match = lines_b[j].strip()\n",
    "                    best_match_index = j\n",
    "            output.write(f\"Text A (line {i + 1}): {line_a.strip()}\\n\")\n",
    "            output.write(f\"Best Match for Text A: {best_match}\\n\")\n",
    "            output.write(f\"Highest N-gram Similarity: {max_similarity:.4f}\\n\\n\")\n",
    "            if best_match_index != -1:\n",
    "                print(f\"Text A (line {i + 1}): {line_a.strip()}\")\n",
    "                print(f\"Best Match for Text A: {lines_b[best_match_index].strip()}\")\n",
    "                print(f\"Highest N-gram Similarity: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ec326-d1f4-45eb-88fa-1766cdfa17c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 部分文字列比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa8ac942-a15b-4e94-a266-f7002e8ed523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_partial_similarity(texts):\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_sim\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    cosine_sim = calculate_partial_similarity(lines_a + lines_b)\n",
    "\n",
    "    output_file = \"partial_similarity_results.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for i, line_a in enumerate(lines_a):\n",
    "            for j, similarity in enumerate(cosine_sim[i][len(lines_a):]):\n",
    "                output.write(f\"Text A (line {i + 1}): {line_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {j + 1}): {lines_b[j].strip()}\\n\")\n",
    "                output.write(f\"Partial Similarity: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8c962b2-846e-4892-b4a3-d9b247cf6e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text A (line 1): 統計のための行列代数DAハーヴィル:8\n",
      "Best Match for Text A: 統計のための行列代数上D・A・ハーヴィル著伊里正夫監訳丸善\n",
      "Highest Partial Similarity: 0.4900\n",
      "\n",
      "Text A (line 2): フィッシャー研究者のための統計的方法RAF・\n",
      "Best Match for Text A: R・A・フィッシャー研究者のための統計的方法R・A・Fisher[著]遠藤健児・鍋谷清治[訳]D908\n",
      "Highest Partial Similarity: 0.5048\n",
      "\n",
      "Text A (line 3): 力学系\n",
      "Best Match for Text A: DYNAMICALSYSTEMS力学系上C・ロビンソン著國府寛司・柴山健伸岡宏枝訳\n",
      "Highest Partial Similarity: 0.1118\n",
      "\n",
      "Text A (line 4): ポイント線形代数四ツ\n",
      "Best Match for Text A: キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Partial Similarity: 0.4264\n",
      "\n",
      "Text A (line 6): キーポイント線形代数四ツ谷\n",
      "Best Match for Text A: キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Partial Similarity: 0.5539\n",
      "\n",
      "Text A (line 7): シリーズ数理統計学の基礎尾畑伸明(\n",
      "Best Match for Text A: クロスセクショナル統計シリーズ1数理統計学の基礎尾畑伸明[著]\n",
      "Highest Partial Similarity: 0.5477\n",
      "\n",
      "Text A (line 9): 入門ベイズ統計松原望\n",
      "Best Match for Text A: 入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "Highest Partial Similarity: 0.4082\n",
      "\n",
      "Text A (line 10): ベイズ統計学\n",
      "Best Match for Text A: やさしく知りたい先端科学シリーズ1ベイズ統計学松原望創元社創元社\n",
      "Highest Partial Similarity: 0.3114\n",
      "\n",
      "Text A (line 11): 人工生命ENER\n",
      "Best Match for Text A: ArtificialLife人工生命改定2版バイオインフォマティクスシリーズ有田隆也[著]医学出版\n",
      "Highest Partial Similarity: 0.1091\n",
      "\n",
      "Text A (line 12): 一一'線型代数入門市藤正接著\n",
      "Best Match for Text A: 数学基礎1線形代数入門斎藤正彦東京大学出版会\n",
      "Highest Partial Similarity: 0.1210\n",
      "\n",
      "Text A (line 13): 解析演習打由无无+青水英里全子兒。因本相大\n",
      "Best Match for Text A: 数学基礎7解析演習杉浦光夫・清水英男金子晃・岡本和夫著東京大学出版会\n",
      "Highest Partial Similarity: 0.0778\n",
      "\n",
      "Text A (line 14): *嗎?解析入門I\n",
      "Best Match for Text A: 数学基礎2解析入門Ⅰ杉浦光夫著東京大学出版会\n",
      "Highest Partial Similarity: 0.1650\n",
      "\n",
      "Text A (line 15): StructureandInterpretationofComputerProgramsSecondEditionAbelsonandSussmanW\n",
      "Best Match for Text A: Structure and Interpretation of Computer Programs Second Edition Abelson and Sussman\n",
      "Highest Partial Similarity: 0.6389\n",
      "\n",
      "Text A (line 16): 微生物の力学系ルスミス竹内ポール・ウォルトマン(著)(日本\n",
      "Best Match for Text A: 微生物の力学系ケモスタット理論を通してハル・スミス＆ポール・ウォルトマン[著]竹内康博[監訳]日本評議院\n",
      "Highest Partial Similarity: 0.3705\n",
      "\n",
      "Text A (line 17): デクステリティ巧みさとそのニコライ・ベルシュタインK\n",
      "Best Match for Text A: デクステリティ巧みさとその発達ニコライ・A・ベルンシュタイン著工藤和俊訳佐々木正人監訳金子書房\n",
      "Highest Partial Similarity: 0.5308\n",
      "\n",
      "Text A (line 18): 理科系の作文技術\n",
      "Best Match for Text A: 理科系の作文技術木下是雄著中公新書624\n",
      "Highest Partial Similarity: 0.5620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_partial_similarity(texts):\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_sim\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    cosine_sim = calculate_partial_similarity(lines_a + lines_b)\n",
    "\n",
    "    output_file = \"partial_similarity_results.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for i, line_a in enumerate(lines_a):\n",
    "            max_similarity = 0.0\n",
    "            best_match = None\n",
    "            best_match_index = -1\n",
    "            for j, similarity in enumerate(cosine_sim[i][len(lines_a):]):\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    best_match = lines_b[j].strip()\n",
    "                    best_match_index = j\n",
    "            output.write(f\"Text A (line {i + 1}): {line_a.strip()}\\n\")\n",
    "            output.write(f\"Best Match for Text A: {best_match}\\n\")\n",
    "            output.write(f\"Highest Partial Similarity: {max_similarity:.4f}\\n\\n\")\n",
    "            if best_match_index != -1:\n",
    "                print(f\"Text A (line {i + 1}): {line_a.strip()}\")\n",
    "                print(f\"Best Match for Text A: {lines_b[best_match_index].strip()}\")\n",
    "                print(f\"Highest Partial Similarity: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54edd8f-1b93-4940-9d31-fc4f5efcd12d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ローマッチング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77f27daa-d48a-4e6b-8dbb-ac1d33133626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def calculate_levenshtein_distance(texts):\n",
    "    distance_matrix = [[0 for _ in range(len(texts[1]))] for _ in range(len(texts[0]))]\n",
    "    for i in range(len(texts[0])):\n",
    "        for j in range(len(texts[1])):\n",
    "            distance_matrix[i][j] = Levenshtein.distance(texts[0][i], texts[1][j])\n",
    "    return distance_matrix\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    levenshtein_distances = calculate_levenshtein_distance([lines_a, lines_b])\n",
    "\n",
    "    output_file = \"levenshtein_distance_results.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for i, line_a in enumerate(lines_a):\n",
    "            for j, distance in enumerate(levenshtein_distances[i]):\n",
    "                similarity = 1 - (distance / max(len(lines_a[i]), len(lines_b[j])))\n",
    "                output.write(f\"Text A (line {i + 1}): {line_a.strip()}\\n\")\n",
    "                output.write(f\"Text B (line {j + 1}): {lines_b[j].strip()}\\n\")\n",
    "                output.write(f\"Levenshtein Similarity: {similarity:.4f}\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "538f1bff-c0eb-47e7-bbd4-76e38cd92d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text A (line 1): 統計のための行列代数DAハーヴィル:8\n",
      "Best Match for Text A: 統計のための行列代数上D・A・ハーヴィル著伊里正夫監訳丸善\n",
      "Highest Levenshtein Similarity: 0.6000\n",
      "\n",
      "Text A (line 2): フィッシャー研究者のための統計的方法RAF・\n",
      "Best Match for Text A: R・A・フィッシャー研究者のための統計的方法R・A・Fisher[著]遠藤健児・鍋谷清治[訳]D908\n",
      "Highest Levenshtein Similarity: 0.4423\n",
      "\n",
      "Text A (line 3): 力学系\n",
      "Best Match for Text A: DYNAMICALSYSTEMS力学系上C・ロビンソン著國府寛司・柴山健伸岡宏枝訳\n",
      "Highest Levenshtein Similarity: 0.0952\n",
      "\n",
      "Text A (line 4): ポイント線形代数四ツ\n",
      "Best Match for Text A: キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Levenshtein Similarity: 0.4583\n",
      "\n",
      "Text A (line 5): a\n",
      "Best Match for Text A: 理科系の作文技術木下是雄著中公新書624\n",
      "Highest Levenshtein Similarity: 0.0476\n",
      "\n",
      "Text A (line 6): キーポイント線形代数四ツ谷\n",
      "Best Match for Text A: キーポイント線形代数薩摩順吉四ツ谷昌二岩波書店\n",
      "Highest Levenshtein Similarity: 0.5833\n",
      "\n",
      "Text A (line 7): シリーズ数理統計学の基礎尾畑伸明(\n",
      "Best Match for Text A: クロスセクショナル統計シリーズ1数理統計学の基礎尾畑伸明[著]\n",
      "Highest Levenshtein Similarity: 0.5312\n",
      "\n",
      "Text A (line 8): a\n",
      "Best Match for Text A: 理科系の作文技術木下是雄著中公新書624\n",
      "Highest Levenshtein Similarity: 0.0476\n",
      "\n",
      "Text A (line 9): 入門ベイズ統計松原望\n",
      "Best Match for Text A: 入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "Highest Levenshtein Similarity: 0.4231\n",
      "\n",
      "Text A (line 10): ベイズ統計学\n",
      "Best Match for Text A: 入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "Highest Levenshtein Similarity: 0.2308\n",
      "\n",
      "Text A (line 11): 人工生命ENER\n",
      "Best Match for Text A: ArtificialLife人工生命改定2版バイオインフォマティクスシリーズ有田隆也[著]医学出版\n",
      "Highest Levenshtein Similarity: 0.1000\n",
      "\n",
      "Text A (line 12): 一一'線型代数入門市藤正接著\n",
      "Best Match for Text A: 数学基礎1線形代数入門斎藤正彦東京大学出版会\n",
      "Highest Levenshtein Similarity: 0.3478\n",
      "\n",
      "Text A (line 13): 解析演習打由无无+青水英里全子兒。因本相大\n",
      "Best Match for Text A: 数学基礎7解析演習杉浦光夫・清水英男金子晃・岡本和夫著東京大学出版会\n",
      "Highest Levenshtein Similarity: 0.2857\n",
      "\n",
      "Text A (line 14): *嗎?解析入門I\n",
      "Best Match for Text A: 数学基礎2解析入門Ⅰ杉浦光夫著東京大学出版会\n",
      "Highest Levenshtein Similarity: 0.2174\n",
      "\n",
      "Text A (line 15): StructureandInterpretationofComputerProgramsSecondEditionAbelsonandSussmanW\n",
      "Best Match for Text A: Structure and Interpretation of Computer Programs Second Edition Abelson and Sussman\n",
      "Highest Levenshtein Similarity: 0.8706\n",
      "\n",
      "Text A (line 16): 微生物の力学系ルスミス竹内ポール・ウォルトマン(著)(日本\n",
      "Best Match for Text A: 微生物の力学系ケモスタット理論を通してハル・スミス＆ポール・ウォルトマン[著]竹内康博[監訳]日本評議院\n",
      "Highest Levenshtein Similarity: 0.4528\n",
      "\n",
      "Text A (line 17): デクステリティ巧みさとそのニコライ・ベルシュタインK\n",
      "Best Match for Text A: デクステリティ巧みさとその発達ニコライ・A・ベルンシュタイン著工藤和俊訳佐々木正人監訳金子書房\n",
      "Highest Levenshtein Similarity: 0.5417\n",
      "\n",
      "Text A (line 18): 理科系の作文技術\n",
      "Best Match for Text A: 理科系の作文技術木下是雄著中公新書624\n",
      "Highest Levenshtein Similarity: 0.3810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def calculate_levenshtein_distance(texts):\n",
    "    distance_matrix = [[0 for _ in range(len(texts[1]))] for _ in range(len(texts[0]))]\n",
    "    for i in range(len(texts[0])):\n",
    "        for j in range(len(texts[1])):\n",
    "            distance_matrix[i][j] = Levenshtein.distance(texts[0][i], texts[1][j])\n",
    "    return distance_matrix\n",
    "\n",
    "def main():\n",
    "    file_a_path = \"output_results.txt\"\n",
    "    file_b_path = \"database.txt\"\n",
    "\n",
    "    with open(file_a_path, \"r\", encoding=\"utf-8\") as file_a:\n",
    "        lines_a = file_a.readlines()\n",
    "\n",
    "    with open(file_b_path, \"r\", encoding=\"utf-8\") as file_b:\n",
    "        lines_b = file_b.readlines()\n",
    "\n",
    "    levenshtein_distances = calculate_levenshtein_distance([lines_a, lines_b])\n",
    "\n",
    "    output_file = \"levenshtein_distance_results.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for i, line_a in enumerate(lines_a):\n",
    "            max_similarity = 0.0\n",
    "            best_match = None\n",
    "            best_match_index = -1\n",
    "            for j, distance in enumerate(levenshtein_distances[i]):\n",
    "                similarity = 1 - (distance / max(len(lines_a[i]), len(lines_b[j])))\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    best_match = lines_b[j].strip()\n",
    "                    best_match_index = j\n",
    "            output.write(f\"Text A (line {i + 1}): {line_a.strip()}\\n\")\n",
    "            output.write(f\"Best Match for Text A: {best_match}\\n\")\n",
    "            output.write(f\"Highest Levenshtein Similarity: {max_similarity:.4f}\\n\\n\")\n",
    "            if best_match_index != -1:\n",
    "                print(f\"Text A (line {i + 1}): {line_a.strip()}\")\n",
    "                print(f\"Best Match for Text A: {lines_b[best_match_index].strip()}\")\n",
    "                print(f\"Highest Levenshtein Similarity: {max_similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "localGPU",
   "language": "python",
   "name": "localgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
