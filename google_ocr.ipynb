{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41c22aa-d628-4037-8f16-e68d16e05e54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf1c2e17-ea96-45fe-b65e-fb272c1f2851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c082f27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T14:53:53.138703Z",
     "start_time": "2023-05-23T14:53:53.097171Z"
    }
   },
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "MIME_TYPE = 'application/vnd.google-apps.document'\n",
    "APPLICATION_NAME = 'ipa-google-drive-api-client'\n",
    "\n",
    "def get_service():\n",
    "\n",
    "    # credentialの取得\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'google-drive-api.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "        \n",
    "    # serviceの取得\n",
    "    service = build('drive', 'v3', credentials=creds) \n",
    "    \n",
    "    return service\n",
    "\n",
    "def read_ocr(service, input_file, lang='en'):\n",
    "    # ファイルのアップロード\n",
    "\n",
    "    # ローカルファイルの定義\n",
    "    media_body = MediaFileUpload(input_file, mimetype=MIME_TYPE, resumable=True)\n",
    "\n",
    "    # Google Drive上のファイル名\n",
    "    newfile = 'output.pdf'\n",
    "\n",
    "    body = {\n",
    "        'name': newfile,\n",
    "        'mimeType': MIME_TYPE\n",
    "    }\n",
    "\n",
    "    # 　creat関数でファイルアップロード実行\n",
    "    # 同時にOCR読み取りも行う\n",
    "    output = service.files().create(\n",
    "        body=body,\n",
    "        media_body=media_body,\n",
    "        # ここで読み込み先言語の指定を行う\n",
    "        ocrLanguage=lang,\n",
    "    ).execute()\n",
    "\n",
    "    # テキストファイルのダウンロード\n",
    "\n",
    "    # リクエストオブジェクト生成\n",
    "    request = service.files().export_media(\n",
    "        fileId=output['id'],\n",
    "        mimeType=\"text/plain\"\n",
    "    )\n",
    "\n",
    "    # 出力用テキストファイル名\n",
    "    output_path = 'output.txt'\n",
    "\n",
    "    with open(output_path, 'a') as f:\n",
    "        fh = io.FileIO(output_path, \"wb\")\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "\n",
    "        service.files().delete(fileId=output['id']).execute()\n",
    "\n",
    "        # テキストの取得\n",
    "    with open(output_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 既存のファイルから読み取り結果を1文にまとめて追記する\n",
    "    output_text = ''.join([line.strip() for line in lines])\n",
    "\n",
    "    with open(output_path, 'a', encoding='utf-8') as f:\n",
    "        f.write(output_text)\n",
    "\n",
    "    # 読み取り結果のリストを返す\n",
    "    return lines[1:]\n",
    "\n",
    "\n",
    "service = get_service()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbdca0-abe2-41e8-ab29-9c0d0a553d1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12ba2b3d-65c6-4721-97e5-8870941f7c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 640 384000\n"
     ]
    }
   ],
   "source": [
    "a,b,_ = cropped_frame.shape\n",
    "print(a,b,cropped_frame.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf8b8d54-f2f9-4d9d-b344-002b96254b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if ret:#カメラと本棚の距離→0.6m\n",
    "    x = 0  # トリミングの左上のX座標\n",
    "    y = 90  # トリミングの左上のY座標\n",
    "    width = 640  # トリミングする幅\n",
    "    height = 200  # トリミングする高さ\n",
    "    \n",
    "    cropped_frame = frame[y:y+height, x:x+width]\n",
    "    resized_frame = cv2.resize(cropped_frame, (480, 150))#効果なかったけどリサイズ幅\n",
    "\n",
    "    cv2.imwrite(\"C:/Users/covid/text_recognition/yolov7/input.png\", cropped_frame)\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebabb2df-4fb9-4d40-a2e8-2a13e0a1ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_frame = cv2.resize(cropped_frame, (480, 150))\n",
    "cv2.imwrite(\"C:/Users/covid/text_recognition/yolov7/input.png\", resized_frame)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ddd81928-34a6-4223-9e45-7c8283efac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\\yolov7\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\covid\\text_recognition\\yolov7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47c2ccd2-7059-4b24-967a-3b588652eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリのパス\n",
    "directory_path = \"C:/Users/covid/text_recognition/yolov7/runs/detect/\"\n",
    "\n",
    "# ディレクトリ内のサブディレクトリのリストを取得\n",
    "subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "# サブディレクトリの中で一番新しいものを取得\n",
    "newest_subdirectory = max(subdirectories, key=lambda d: os.path.getctime(os.path.join(directory_path, d)))\n",
    "\n",
    "# 最新のサブディレクトリのパスを作成\n",
    "newest_subdirectory_path = os.path.join(directory_path, newest_subdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f3504fcd-93e7-427a-944d-161d4f3b56fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['yolov7-e6e.pt'], source='C:/Users/covid/text_recognition/yolov7/input.png', img_size=1280, conf_thres=0.25, iou_thres=0.45, device='0', view_img=False, save_txt=True, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
      "Fusing layers... \n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "20 books, Done. (26.0ms) Inference, (45.3ms) NMS\n",
      " The image with the result is saved in: runs\\detect\\exp6\\input.png\n",
      "Done. (0.477s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  v0.1-126-g84932d7 torch 2.1.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "Model Summary: 792 layers, 151687420 parameters, 817020 gradients\n",
      "C:\\Users\\covid\\anaconda3\\envs\\localGPU\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source C:/Users/covid/text_recognition/yolov7/input.png --weights yolov7-e6e.pt --conf 0.25 --img-size 1280 --device 0 --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1820bb9-6774-4ac4-8085-ab3c7f8ec3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリのパス\n",
    "directory_path = \"C:/Users/covid/text_recognition/yolov7/runs/detect/\"\n",
    "\n",
    "# ディレクトリ内のサブディレクトリのリストを取得\n",
    "subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "# サブディレクトリの中で一番新しいものを取得\n",
    "newest_subdirectory = max(subdirectories, key=lambda d: os.path.getctime(os.path.join(directory_path, d)))\n",
    "\n",
    "# 最新のサブディレクトリのパスを作成\n",
    "newest_subdirectory_path = os.path.join(directory_path, newest_subdirectory)\n",
    "\n",
    "# 新しいディレクトリに移動\n",
    "os.chdir(newest_subdirectory_path)\n",
    "\n",
    "# 画像ファイルの相対パスを指定\n",
    "image_relative_path = \"input.png\"\n",
    "# テキストファイルの相対パスを指定\n",
    "text_file_relative_path = \"labels/input.txt\"\n",
    "\n",
    "# 画像ファイルの絶対パスを作成\n",
    "image_absolute_path = os.path.join(newest_subdirectory_path, image_relative_path)\n",
    "# テキストファイルの絶対パスを作成\n",
    "text_file_absolute_path = os.path.join(newest_subdirectory_path, text_file_relative_path)\n",
    "\n",
    "# 画像をImageクラスのインスタンスに読み込む\n",
    "image = Image.open(image_absolute_path)\n",
    "# テキストファイルを読み込む\n",
    "with open(text_file_absolute_path, 'r') as file:\n",
    "    text_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c3ce4be-c3e3-48a1-83cb-b1c2c067f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "wid,hei = image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e30fd2d9-71f2-47b1-a602-2b1d9b7c14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_file(text_file):\n",
    "    output_dir = \"C:/Users/covid/text_recognition/output\"\n",
    "    if os.path.exists(output_dir):\n",
    "        file_list = [f for f in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, f))]\n",
    "        for file_name in file_list:\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "            os.remove(file_path)\n",
    "    else:\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with open(text_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        lines = sorted(lines, key=lambda line: float(line.split()[1]))\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            values = line.split()\n",
    "\n",
    "            if len(values) == 5:\n",
    "                object_class = values[0]\n",
    "                a = float(values[1])\n",
    "                b = float(values[2])\n",
    "                c = float(values[3])\n",
    "                d = float(values[4])\n",
    "\n",
    "                # Calculate coordinates and dimensions\n",
    "                x_center = int(wid * a)\n",
    "                y_center = int(hei * b)\n",
    "                width = int(wid * c)\n",
    "                height = int(hei * d)\n",
    "\n",
    "                x_min = x_center - width // 2\n",
    "                y_min = y_center - height // 2\n",
    "                x_max = x_center + width // 2\n",
    "                y_max = y_center + height // 2\n",
    "\n",
    "                output_filename = os.path.join(output_dir, f'book{i+1}.jpg')\n",
    "                index = 1\n",
    "                while os.path.exists(output_filename):\n",
    "                    output_filename = os.path.join(output_dir, f'book{i+1}_{index}.jpg')\n",
    "                    index += 1\n",
    "\n",
    "                # Crop and save the image\n",
    "                cropped = image.crop((x_min, y_min, x_max, y_max))\n",
    "                cropped.save(output_filename)\n",
    "\n",
    "# Process the text file\n",
    "process_text_file(text_file_absolute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a56d76ea-5fcc-49fa-97d4-2e7f088dd256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covid\\text_recognition\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\covid\\text_recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa5e5781-5c29-47ee-84b7-2f6160a35a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "キーポイント線形代数2薩摩順吉四ツ谷晶二岩波書店\n",
      "クロスセクショナル統計シリーズ数理統計学の基礎尾畑伸明[著]KYORITSUSHUPPAN\n",
      "series先輩が01教える実験データ処理Excel活用法はじめて使うExcelのちょっとした入門書嶋貫健司著大塚礼雄協力CUTTカットシステム\n",
      "MLP学習プロフェッショナルシリーズ異常検知と変化検知井手剛杉山将講談社講談社\n",
      "入門ベイズ統計意思決定の理論と発展松原望著東京図書\n",
      "やさしく知りたい先端科学シリーズ1ベイズ統計学松原望創元社創元社\n",
      "AI人工生命八ㄔㄤPIㄅㄡ·彭雯有田隆也改訂2版......[著]医学出版\n",
      "数学線型代数入門齋藤正彥著東京大学出版会\n",
      "基礎数学7解析演習杉浦光夫·清水英男金子晃·岡本和夫著東京大学出版会\n",
      "基礎数学2解析入門杉浦光夫著学会東出\n",
      "StructureandInterpretationofComputerProgramsSecondEditionAbelsonandSussman\n",
      "DYNAMICALSYSTEMS力学系A國府寬司·柴山健伸岡宏枝訳S\n",
      "DYNAMICALSYSTEMS力学系下C・ロビンソン著國府司・柴山健伸寛岡宏枝訳\n",
      "機械振動学動的問題解決基本知識佐藤豚秀紀岡部佐規一共著岩田佳雄元工業調査会\n",
      "実践ロボット制御基礎から動力学まで細田耕[著]HosodaKoh株式会社アールティ[協力]RTCorporationOhmsha\n",
      "R・A・フィッシャー研究者のための統計的方法R.A.Fisher[著]遠藤健児・鍋谷清治[訳]e0908\n",
      "Aプログラミングスマートスピーカー×自分でつくる人工知能AmazonEcho.GoogleHomeポンダッド[著]W.マイナビ\n",
      "情報理論と符号理論G・A・ジョーンズJ・M・ジョーンズ一樂重雄河原正治河原雅子訳著丸善3\n",
      "はじめてのパターン認識を平井有三著8497\n",
      "パターン認識と機械学習上いベイズ理論による統計的予測C・M・ビショップ著元田浩栗田多喜夫樋口知之松本裕治村田昇監訳遥丸善\n",
      "パターン認識と機械学習下ベイズ理論による統計的予測C・M・ビショップ著元田浩栗田多喜夫樋口知之松本裕治村田昇監訳丸善\n",
      "マルコフ連鎖から格子確率モデルへR・B・シナジ著現代確率論の基礎と応用今野紀雄林俊一訳\n",
      "MLS機械学習スタートアップシリーズベイズ推論による機械学習門須山敦志著杉山将監修講談社\n",
      "MLPP機械学習プロフェッショナルシリーズ変分ベイズ学習天地劣黄共中島伸講談社O\n",
      "2学習MLPシリーズプロフェッショナルスパース性に基づく機械学習プロフェッショナル劣モジュラ最進化と機械学習冨岡亮太講談社\n",
      "MLPP機械学習シリーズプロフェッショナル劣モジュラ最適化と機械学習河原吉伸永野清仁講談社講談社\n",
      "MLPP機械学習プロフェッショナルシリーズトピックモデルナーチ岩田具治\n",
      "情報・技術経営シリーズ経営情報処理のための工学博士栗原謙三オペレーションズリサーチ共著工学博士明石吉三CORONAwwwwwコロナ社\n",
      "KINECTHACKER'SMANUAL本木クトハッカーズマニュアル西林孝小野憲史著RutlesLZ\n"
     ]
    }
   ],
   "source": [
    "#output corresponding to list format\n",
    "if __name__ == '__main__':\n",
    "    directory_path = 'C:/Users/covid/text_recognition/yolov7/output'\n",
    "    output_list = []\n",
    "\n",
    "    file_list = [filename for filename in os.listdir(directory_path) if filename.endswith('.jpg')]\n",
    "    file_list.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "    for filename in file_list:\n",
    "        input_file = os.path.join(directory_path, filename)\n",
    "        output = read_ocr(service, input_file, 'ja')\n",
    "\n",
    "        # 不要な文字（スペースとバックスラッシュ）を除去して一つの文字列に結合する\n",
    "        cleaned_output = ''.join(line.strip().replace(' ', '').replace('/', '').replace('\\n', '').replace('\\\\', '') for line in output)\n",
    "\n",
    "        # 結果をリストに追加\n",
    "        output_list.append(cleaned_output)\n",
    "\n",
    "    # 結果のリストを出力\n",
    "    for result in output_list:\n",
    "        print(result)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "localGPU",
   "language": "python",
   "name": "localgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
